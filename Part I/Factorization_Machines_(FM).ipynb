{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Factorization Machines (FM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8IxcFFpGx1L"
      },
      "source": [
        "# Factorization Machines \r\n",
        "\r\n",
        "Factorization machines (FM) is a supervised algorithm that can be used for classification, regression, and ranking tasks. Particularly, it is a generalization of the linear regression model and the matrix factorization model. \r\n",
        "\r\n",
        "FM is formulated as a linear model, with interactions between features as additional parameters (features). However, these user/item indicators can be augmented with arbitrary auxiliary features, for example, user or item attributes and/or contextual features relevant to the interaction itself. These feature interactions are done in their latent space representation instead of their plain format.\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?id=1-1ywT0sOGrYs8lXJ-zljSrF2mF6gQxvS)\r\n",
        "\r\n",
        "* A linear model, given a vector *x* models its output *y* as: \r\n",
        "\r\n",
        "  ![](https://drive.google.com/uc?id=1U1HUGuROvvxHQ-abyJHx5HgoQvd7ExDD)\r\n",
        "  \r\n",
        "  where *w* are the learnable weights of the model.\r\n",
        "\r\n",
        "  The drawback of this model is that it does not handle feature interactions. To capture interactions, we could introduce a weight *wui* for each feature combination (that combines both user *u* and movie (item) *i* interaction).\r\n",
        "\r\n",
        "*  The resulting model for a factorization machine of degree two is defined as:\r\n",
        "![](https://drive.google.com/uc?id=1W_ndd8TORVF_3zFk40wNifBPZYtPP0jo)\r\n",
        "\r\n",
        "   Compared to our previous model, this formulation has the advantages that it can capture feature interactions at least for two features at a time. However, this introduces a large number of *w2* variables.\r\n",
        "\r\n",
        "* To solve this complexity issue, Factorization Machines takes inspiration from matrix factorization, and models the feature interaction using latent factors.Therefore previous equiation can be  re-formulation as low-rank re-formulation to reduce the number of additional parameters for the factorization machine.\r\n",
        "\r\n",
        "  ![](https://drive.google.com/uc?id=1L9cx5gghNPaf_FpTCWj6EwhS6--FhAMg)\r\n",
        "\r\n",
        "  The first two terms correspond to the linear regression model and the last term is an extension of the matrix factorization model. If the feature *i*  represents an item and the feature *j*  represents a user, the third term is exactly the dot product between user and item embeddings. \r\n",
        "-------------------------------\r\n",
        "**Advantages:** We'll now wrap up the theoretical section of factorization machine, with some of its advantages:\r\n",
        "\r\n",
        "* We can observe from the model equation that it can be computed in linear time.\r\n",
        "* By leveraging ideas from matrix factorization, we can estimate higher order interaction effects even under very sparse data.\r\n",
        "* Compared to traditional matrix factorization methods, which is restricted to modeling a user-item matrix, we can leverage other user or item specific features making factorization machine more flexible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7palkAIRf4L9"
      },
      "source": [
        "# Model implementation in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wjfQ9PYy0E5"
      },
      "source": [
        "# import libraries\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.utils import shuffle\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "torch.manual_seed(2020)\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX7GzwMFOZC8"
      },
      "source": [
        "# Initialize a Loader class\r\n",
        "class Loader():\r\n",
        "    # Set the iterator\r\n",
        "    current = 0\r\n",
        "\r\n",
        "    def __init__(self, x, y, batchsize=1024, do_shuffle=True):\r\n",
        "        \"\"\"\r\n",
        "        :param x: features\r\n",
        "        :param y: target\r\n",
        "        :param batchsize: batch size = 1024\r\n",
        "        :param do_shuffle: shuffle mode turned on\r\n",
        "        \"\"\"\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.x = x\r\n",
        "        self.y = y\r\n",
        "        self.batchsize = batchsize\r\n",
        "        self.batches = range(0, len(self.y), batchsize)\r\n",
        "        if do_shuffle:\r\n",
        "            # Every epoch re-shuffle the dataset\r\n",
        "            self.x, self.y = shuffle(self.x, self.y)\r\n",
        "\r\n",
        "    def __iter__(self):\r\n",
        "        # Reset & return a new iterator\r\n",
        "        self.x, self.y = shuffle(self.x, self.y, random_state=0)\r\n",
        "        self.current = 0\r\n",
        "        return self\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        # Return the number of batches\r\n",
        "        return int(len(self.x) / self.batchsize)\r\n",
        "\r\n",
        "    def __next__(self):\r\n",
        "        # Update iterator and stop iteration until the batch size is out of range\r\n",
        "        n = self.batchsize\r\n",
        "        if self.current + n >= len(self.y):\r\n",
        "            raise StopIteration\r\n",
        "        i = self.current\r\n",
        "\r\n",
        "        # Transform NumPy arrays to PyTorch tensors\r\n",
        "        xs = torch.from_numpy(self.x[i:i + n])\r\n",
        "        ys = torch.from_numpy(self.y[i:i + n])\r\n",
        "        self.current += n\r\n",
        "        return xs, ys\r\n",
        "    \r\n",
        "def index_into(arr, idx):\r\n",
        "    new_shape = (idx.size()[0], idx.size()[1], arr.size()[1])\r\n",
        "    return arr[idx.resize(torch.numel(idx.data))].view(new_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXU-FnjQgdoM"
      },
      "source": [
        "We can reorganize the third term of FM which could greatly reduce the computation cost, leading to a linear time complexity. The reformulation of the pairwise interaction term is as follows:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAlHOSWggb6"
      },
      "source": [
        "def factorization_machine(v, x=None):\r\n",
        "    \"\"\"\r\n",
        "    Takes an input 2D matrix v of n vectors, each d-dimensional\r\n",
        "    :param v: (batchsize, n_features, dim)\r\n",
        "    :param x: (batchsize, n_features) functions as a weight array, assumed to be 1 if missing\r\n",
        "    :return: output that is d-dimensional\r\n",
        "    \"\"\"\r\n",
        "    batchsize = v.size()[0]\r\n",
        "    n_features = v.size()[1]\r\n",
        "    n_dim = v.size()[2]\r\n",
        "\r\n",
        "    if x is None:\r\n",
        "        x = Variable(torch.ones(v.size()))\r\n",
        "    else:\r\n",
        "        x = x.expand(batchsize, n_features, n_dim)\r\n",
        "\r\n",
        "    # Uses Rendle's trick for computing pairs of features in linear time\r\n",
        "    square_of_sum  = (v * x).sum(dim=1) ** 2.0\r\n",
        "    sum_of_square  = (v ** 2.0 * x ** 2.0).sum(dim=1)\r\n",
        "    return 0.5 * (square_of_sum  - sum_of_square )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9pK5V9EOZO2"
      },
      "source": [
        "class FM(nn.Module):\r\n",
        "    # Iteration counter\r\n",
        "    itr = 0\r\n",
        "\r\n",
        "    def __init__(self, n_feat, k=10, c_feat=1.0, c_bias=1.0, writer=None):\r\n",
        "        \"\"\"\r\n",
        "        :param n_feat: Feature column\r\n",
        "        :param k: Dimensions constant\r\n",
        "        :param c_feat: Regularization constant for the features\r\n",
        "        :param c_bias: Regularization constant for the biases\r\n",
        "        :param writer: Log results via TensorBoard\r\n",
        "        \"\"\"\r\n",
        "        super(FM, self).__init__()\r\n",
        "\r\n",
        "        # This will hold the logging\r\n",
        "        self.writer = writer\r\n",
        "\r\n",
        "        # These are the hyper-parameters\r\n",
        "        self.k = k\r\n",
        "        self.n_feat = n_feat\r\n",
        "        self.c_feat = c_feat\r\n",
        "        self.c_bias = c_bias\r\n",
        "\r\n",
        "        # The embedding matrices for the features and the feature's biases\r\n",
        "        self.feat = nn.Embedding(n_feat, k)\r\n",
        "        self.bias_feat = nn.Embedding(n_feat, 1)\r\n",
        "\r\n",
        "    def __call__(self, train_x):\r\n",
        "        \"\"\"This is the most important function in this script\"\"\"\r\n",
        "        # Pull out biases\r\n",
        "        biases = index_into(self.bias_feat.weight, train_x).squeeze().sum(dim=1)\r\n",
        "\r\n",
        "        # Initialize vector features using the feature weights\r\n",
        "        vector_features = index_into(self.feat.weight, train_x)\r\n",
        "\r\n",
        "        # Use factorization machines to pull out the interactions\r\n",
        "        interactions = factorization_machine(vector_features).squeeze().sum(dim=1)\r\n",
        "\r\n",
        "        # Final prediction is the sum of biases and interactions\r\n",
        "        prediction = biases + interactions\r\n",
        "        return prediction\r\n",
        "\r\n",
        "    def loss(self, prediction, target):\r\n",
        "        \"\"\"\r\n",
        "        Function to calculate the loss metric\r\n",
        "        \"\"\"\r\n",
        "        # Calculate the Mean Squared Error between target and prediction\r\n",
        "        loss_mse = F.mse_loss(prediction.squeeze(), target.squeeze())\r\n",
        "\r\n",
        "        # Compute L2 regularization over feature matrices\r\n",
        "        prior_feat = l2_regularize(self.feat.weight) * self.c_feat\r\n",
        "\r\n",
        "        # Add the MSE loss and feature regularization to get total loss\r\n",
        "        total = (loss_mse + prior_feat)\r\n",
        "\r\n",
        "        # This logs all local variables to tensorboard\r\n",
        "        for name, var in locals().items():\r\n",
        "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\r\n",
        "                self.writer.add_scalar(name, var, self.itr)\r\n",
        "        return total\r\n",
        "\r\n",
        "# FMs are prone to overfitting and for this reason L2 regularization is applied\r\n",
        "def l2_regularize(array):\r\n",
        "    \"\"\"\r\n",
        "    Function to do L2 regularization\r\n",
        "    \"\"\"\r\n",
        "    loss = torch.sum(array ** 2.0)\r\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycxyv0vxg-BS",
        "outputId": "51dac20e-e784-4fb0-b8ca-ad08cb7b120d"
      },
      "source": [
        "# get the data\r\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\r\n",
        "!unzip ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-09 09:26:42--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip.3’\n",
            "\n",
            "ml-1m.zip.3         100%[===================>]   5.64M  12.6MB/s    in 0.4s    \n",
            "\n",
            "2021-02-09 09:26:43 (12.6 MB/s) - ‘ml-1m.zip.3’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "replace ml-1m/movies.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "uHMVxycaOZRA",
        "outputId": "2e62ae79-5afe-4ae4-9e6e-c2564dd243f1"
      },
      "source": [
        "# read the data\r\n",
        "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', engine='python', \r\n",
        "                      names=('userId', 'movieId','ratings','timestamp'))\r\n",
        "\r\n",
        "# Create users dataframe\r\n",
        "users = pd.read_csv(\"./ml-1m/users.dat\", sep='::', engine='python',\r\n",
        "                    names=['userId', 'gender', 'age', 'occupation', 'zipcode'])\r\n",
        "\r\n",
        "# Create users dataframe\r\n",
        "movies = pd.read_csv(\"./ml-1m/movies.dat\", sep='::', engine='python',\r\n",
        "                    names=['movieId', 'title', 'genres_str'])\r\n",
        "\r\n",
        "# Is this rating the first rating ever for that user, or the nth?\r\n",
        "ratings['rank'] = ratings.groupby(\"userId\")[\"timestamp\"].rank(ascending=True).astype('int64')\r\n",
        "\r\n",
        "# Merge ratings & user features\r\n",
        "dataset = ratings.merge(users, on='userId')\r\n",
        "dataset = dataset.merge(movies, on='movieId')\r\n",
        "dataset = dataset.sample(frac=1)\r\n",
        "dataset.drop(columns=['timestamp', 'zipcode', 'title', 'genres_str'], inplace=True)\r\n",
        "dataset['gender'] = dataset['gender'].map({'M':0, 'F':1})\r\n",
        "assert len(ratings) == len(dataset)\r\n",
        "\r\n",
        "# Compute cardinalities\r\n",
        "n_user = dataset.userId.max() + 1\r\n",
        "n_item = dataset.movieId.max() + 1\r\n",
        "n_rank = dataset['rank'].max() + 1\r\n",
        "n_age = dataset['age'].max() + 1\r\n",
        "n_occu = dataset['occupation'].max() + 1\r\n",
        "n_gen = dataset['gender'].nunique()\r\n",
        "# n_feat = n_user + n_item + n_rank + n_age + n_occu + n_gen\r\n",
        "n_feat = n_user + n_item + n_occu + n_rank\r\n",
        "\r\n",
        "print('n_user', n_user)\r\n",
        "print('n_item', n_item)\r\n",
        "print('n_rank', n_rank)\r\n",
        "print('n_gen', n_gen)\r\n",
        "print('n_age', n_age)\r\n",
        "print('n_occu', n_occu)\r\n",
        "print('n_feat', n_feat)\r\n",
        "print('n_rows', len(dataset))\r\n",
        "\r\n",
        "display(dataset.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_user 6041\n",
            "n_item 3953\n",
            "n_rank 2315\n",
            "n_gen 2\n",
            "n_age 57\n",
            "n_occu 21\n",
            "n_feat 12330\n",
            "n_rows 1000209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rank</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>511229</th>\n",
              "      <td>329</td>\n",
              "      <td>1200</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767023</th>\n",
              "      <td>3174</td>\n",
              "      <td>804</td>\n",
              "      <td>3</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111551</th>\n",
              "      <td>5015</td>\n",
              "      <td>1225</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341264</th>\n",
              "      <td>4379</td>\n",
              "      <td>1441</td>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633718</th>\n",
              "      <td>3646</td>\n",
              "      <td>198</td>\n",
              "      <td>2</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  ratings  rank  gender  age  occupation\n",
              "511229     329     1200        5    90       0   35           7\n",
              "767023    3174      804        3    53       1   18          14\n",
              "111551    5015     1225        4    66       0   35           6\n",
              "341264    4379     1441        4    60       0   25           4\n",
              "633718    3646      198        2    71       0   35          20"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vPCF1YwOZT7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "\r\n",
        "# split the dataset into training and testing datasets\r\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.1, random_state=42, stratify=dataset.ratings)\r\n",
        "\r\n",
        "train_df.loc[:, 'movieId'] = n_user\r\n",
        "train_df.loc[:, 'rank'] = n_user + n_item\r\n",
        "train_df.loc[:, 'occupation'] = n_user + n_item + n_occu\r\n",
        "# train_df.loc[:, 'gender'] = n_user + n_item + n_rank\r\n",
        "# train_df.loc[:, 'age'] = n_user + n_item + n_rank + n_gen\r\n",
        "# train_df.loc[:, 'occupation'] = n_user + n_item + n_rank + n_gen + n_age\r\n",
        "\r\n",
        "test_df.loc[:, 'movieId'] = n_user\r\n",
        "test_df.loc[:, 'rank'] = n_user + n_item\r\n",
        "test_df.loc[:, 'occupation'] = n_user + n_item + n_occu\r\n",
        "# test_df.loc[:, 'gender'] = n_user + n_item + n_rank\r\n",
        "# test_df.loc[:, 'age'] = n_user + n_item + n_rank + n_gen\r\n",
        "# test_df.loc[:, 'occupation'] = n_user + n_item + n_rank + n_gen + n_age\r\n",
        "\r\n",
        "train_X = torch.tensor(train_df[['userId', 'movieId', 'rank', 'occupation']].values)\r\n",
        "train_y = torch.FloatTensor(train_df['ratings'].values)\r\n",
        "test_x = torch.tensor(test_df[['userId', 'movieId', 'rank', 'occupation']].values)\r\n",
        "test_y = torch.FloatTensor(test_df['ratings'].values)\r\n",
        "\r\n",
        "train_loader = DataLoader(TensorDataset(train_X, train_y), batch_size=1024)\r\n",
        "test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZsfaz-thnO_"
      },
      "source": [
        "losses = []\r\n",
        "\r\n",
        "# fit the model to the input data and label.\r\n",
        "def fit(model, dataloader, optimizer):\r\n",
        "    model.train()\r\n",
        "    # for epoch in range(epochs):\r\n",
        "    for batch in dataloader:\r\n",
        "        optimizer.zero_grad()\r\n",
        "        x, y = batch[0], batch[1]\r\n",
        "        y_pred = model(x)\r\n",
        "        loss = model.loss(y_pred, y)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "    # print(f\"epoch {epoch}'s training loss %.3f\" % loss.item())\r\n",
        "    # losses.append(loss.item())\r\n",
        "    return loss.item()\r\n",
        "\r\n",
        "# evaluate the model on unseen data\r\n",
        "def evaluate(model, dataloader):\r\n",
        "    model.eval()\r\n",
        "    for batch in dataloader:\r\n",
        "        with torch.no_grad():\r\n",
        "            x, y = batch[0], batch[1]\r\n",
        "            y_pred = model(x)\r\n",
        "            loss = model.loss(y_pred, y)\r\n",
        "    # print(\"test loss %.3f \" % loss.item())\r\n",
        "    # return y_pred, y\r\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcBY--uvhnSN"
      },
      "source": [
        "# Define the Hyper-parameters\r\n",
        "lr = 1e-2  # Learning rate\r\n",
        "k = 10  # Number of dimensions per user and item\r\n",
        "c_bias = 1e-5  # Bias constant\r\n",
        "c_feat = 1e-5  # Regularization constant\r\n",
        "epochs = 10\r\n",
        "# Instantiate the model class object\r\n",
        "model = FM(n_feat, k=k, c_bias=c_bias, c_feat=c_feat)\r\n",
        "\r\n",
        "# Use Adam optimizer\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "\r\n",
        "# fit(model, epochs=10, dataloader=train_loader, optimizer=optimizer)\r\n",
        "# evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeHaZCAwWyfd",
        "outputId": "672edb65-da4f-42fc-b11b-77ec77e5ef94"
      },
      "source": [
        "# Loop through pre-defined number of epochs\r\n",
        "train_losses = []\r\n",
        "test_losses = []\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "    # Perform training on the train set\r\n",
        "    train_loss = fit(model, dataloader=train_loader, optimizer=optimizer)\r\n",
        "    # Perform evaluation on the validation set\r\n",
        "    # valid_auc = test(model, valid_data_loader, device)\r\n",
        "    # Log the epochs and AUC on the validation set\r\n",
        "    print('epoch:', epoch, 'training loss:', train_loss)\r\n",
        "    train_losses.append(train_loss)\r\n",
        "\r\n",
        "    # Perform evaluation on the test set\r\n",
        "    test_loss = evaluate(model, test_loader)\r\n",
        "    # Log the final MSE loss on the test set\r\n",
        "    print('epoch:', epoch, 'testing  loss:', test_loss)\r\n",
        "    test_losses.append(test_loss)\r\n",
        "\r\n",
        "# Save the model checkpoint\r\n",
        "torch.save(model.state_dict(), 'mf.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 training loss: 1.5841721296310425\n",
            "epoch: 0 testing  loss: 1.5758739709854126\n",
            "epoch: 1 training loss: 1.4656462669372559\n",
            "epoch: 1 testing  loss: 1.4520232677459717\n",
            "epoch: 2 training loss: 1.389354944229126\n",
            "epoch: 2 testing  loss: 1.3434208631515503\n",
            "epoch: 3 training loss: 1.3236620426177979\n",
            "epoch: 3 testing  loss: 1.2623251676559448\n",
            "epoch: 4 training loss: 1.2694118022918701\n",
            "epoch: 4 testing  loss: 1.208667278289795\n",
            "epoch: 5 training loss: 1.2306150197982788\n",
            "epoch: 5 testing  loss: 1.1725738048553467\n",
            "epoch: 6 training loss: 1.2054029703140259\n",
            "epoch: 6 testing  loss: 1.1478619575500488\n",
            "epoch: 7 training loss: 1.1735032796859741\n",
            "epoch: 7 testing  loss: 1.1339900493621826\n",
            "epoch: 8 training loss: 1.1250455379486084\n",
            "epoch: 8 testing  loss: 1.1278533935546875\n",
            "epoch: 9 training loss: 1.0620251893997192\n",
            "epoch: 9 testing  loss: 1.1209110021591187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "WHirNA8QhnVU",
        "outputId": "5f6706a7-d2e7-4bed-a177-e7623e0de55c"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "plt.plot( train_losses, 'b', label='Training loss')\r\n",
        "plt.plot( test_losses, 'r', label='Testing loss')\r\n",
        "plt.title('Training and Test loss')\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsQaITYdwA1"
      },
      "source": [
        "# Undertanding Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1iTnjPqty3w",
        "outputId": "bfb2ff43-91a7-46ca-cadb-f105c806ad11"
      },
      "source": [
        "# explore the features embedding matrix weights\r\n",
        "feat_weight = model.feat.weight\r\n",
        "print(feat_weight.size())\r\n",
        "print(feat_weight[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12330, 10])\n",
            "tensor([ 5.8606e-38, -2.2490e-39, -3.5130e-40, -6.5776e-38,  3.3245e-39,\n",
            "         3.6953e-39, -1.6310e-39,  8.6407e-40, -1.6005e-39,  1.6225e-39],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP_i-Kf8uWpH",
        "outputId": "a248bffe-257f-4f86-cfd5-b657df3c90d8"
      },
      "source": [
        "# explore the biases embedding matrix weights\r\n",
        "bias_weight = model.bias_feat.weight\r\n",
        "print(bias_weight.size())\r\n",
        "print(bias_weight[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12330, 1])\n",
            "tensor([-0.7479], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKbGxysIngET",
        "outputId": "9bb871ab-ce4f-4fc4-8495-b938f6a9f5aa"
      },
      "source": [
        "# one batch of train loader looks like\r\n",
        "next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 3553,  6041,  9994, 10015],\n",
              "         [ 5394,  6041,  9994, 10015],\n",
              "         [ 1733,  6041,  9994, 10015],\n",
              "         ...,\n",
              "         [ 3724,  6041,  9994, 10015],\n",
              "         [ 6016,  6041,  9994, 10015],\n",
              "         [  319,  6041,  9994, 10015]]),\n",
              " tensor([5., 3., 4.,  ..., 4., 4., 4.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq-cu-hVKkPf",
        "outputId": "f75b99d4-24c6-45e6-a308-6464b50c220a"
      },
      "source": [
        "for i, batch in enumerate(train_loader):\r\n",
        "  if i == 0:\r\n",
        "    x, y = batch[0], batch[1]\r\n",
        "    print(x)\r\n",
        "    print(x.size())\r\n",
        "    print(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3553,  6041,  9994, 10015],\n",
            "        [ 5394,  6041,  9994, 10015],\n",
            "        [ 1733,  6041,  9994, 10015],\n",
            "        ...,\n",
            "        [ 3724,  6041,  9994, 10015],\n",
            "        [ 6016,  6041,  9994, 10015],\n",
            "        [  319,  6041,  9994, 10015]])\n",
            "torch.Size([1024, 4])\n",
            "tensor([ 3553,  6041,  9994, 10015])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCdLjCqMtm0A",
        "outputId": "aba561c8-6f08-4409-f2df-d6bd687a529f"
      },
      "source": [
        "# get vector features using the index from 2-dimensonal (number of features, k-factor) feature weights matrix\r\n",
        "vector_features = index_into(feat_weight, train_X)\r\n",
        "print(len(vector_features))\r\n",
        "print(vector_features[0])\r\n",
        "print(vector_features.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "tensor([[-0.0216, -0.1484, -0.0029,  0.0098, -0.0145,  0.0557, -0.0784, -0.0334,\n",
            "         -0.0185,  0.0893],\n",
            "        [-0.3381,  0.2245,  0.0861, -0.0604,  0.1734, -0.0088,  0.0145,  0.0521,\n",
            "          0.1075,  0.0337],\n",
            "        [ 0.2059,  0.4398,  0.0466, -0.1078,  0.1676, -0.0954,  0.0074,  0.1455,\n",
            "          0.1521, -0.0092],\n",
            "        [ 0.2095, -0.4076,  0.0744,  0.0286, -0.0101,  0.1766,  0.0030,  0.1543,\n",
            "         -0.0262,  0.0357]], grad_fn=<SelectBackward>)\n",
            "torch.Size([900188, 4, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BREv15DUvhkv",
        "outputId": "c1e2489d-bbcd-420b-9093-57f1b7bd13d1"
      },
      "source": [
        "# compute interactions using usign Rendle's trick \r\n",
        "interactions = factorization_machine(vector_features).squeeze().sum(dim=1)\r\n",
        "print(len(interactions))\r\n",
        "print(interactions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "tensor([-0.2525, -0.7502, -0.1460,  ..., -0.4911,  0.3138,  0.1202],\n",
            "       grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9vL-kcSvmLk",
        "outputId": "5ce795a5-5ab2-4eb1-ef64-88369e5679c9"
      },
      "source": [
        "# get baiases from bias weights matrix\r\n",
        "biases = index_into(bias_weight, train_X).squeeze().sum(dim=1)\r\n",
        "print(len(biases))\r\n",
        "print(biases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "tensor([4.3203, 4.2266, 3.8609,  ..., 3.4280, 3.9510, 4.0620],\n",
            "       grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whdHQ6B_v3oq",
        "outputId": "4d47aade-b1d1-484d-ce88-eef670e30910"
      },
      "source": [
        "# compute final predictions by summing bias and interaction\r\n",
        "prediction = biases + interactions\r\n",
        "print(prediction)\r\n",
        "print(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4.0678, 3.4764, 3.7149,  ..., 2.9370, 4.2648, 4.1822],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([5., 3., 4.,  ..., 4., 5., 5.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-vrHXCDzOe5",
        "outputId": "b7672ab1-84e1-4aa8-bdee-0a14e7d97dd2"
      },
      "source": [
        "print(len(prediction))\r\n",
        "print(len(train_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "900188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBmxUDklVh9"
      },
      "source": [
        "We can see that the model reconstructs original ratings nor that well. Things we can try to improve that:\r\n",
        "\r\n",
        "* Get more data\r\n",
        "* Tune hyper-patameters (especially k-factor)\r\n",
        "* Train the model for more epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd_SyyDpdxCk"
      },
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "yNhMQzkK58yj",
        "outputId": "b75202a0-c48c-4197-9300-b0015b37c5af"
      },
      "source": [
        "dataset[dataset.userId == 5533]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rank</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>340043</th>\n",
              "      <td>5533</td>\n",
              "      <td>266</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516854</th>\n",
              "      <td>5533</td>\n",
              "      <td>969</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633356</th>\n",
              "      <td>5533</td>\n",
              "      <td>2173</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894409</th>\n",
              "      <td>5533</td>\n",
              "      <td>1913</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679053</th>\n",
              "      <td>5533</td>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628529</th>\n",
              "      <td>5533</td>\n",
              "      <td>1185</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30936</th>\n",
              "      <td>5533</td>\n",
              "      <td>1097</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21527</th>\n",
              "      <td>5533</td>\n",
              "      <td>2797</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79302</th>\n",
              "      <td>5533</td>\n",
              "      <td>1217</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564107</th>\n",
              "      <td>5533</td>\n",
              "      <td>3101</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86814</th>\n",
              "      <td>5533</td>\n",
              "      <td>902</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205117</th>\n",
              "      <td>5533</td>\n",
              "      <td>1304</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630697</th>\n",
              "      <td>5533</td>\n",
              "      <td>247</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491029</th>\n",
              "      <td>5533</td>\n",
              "      <td>858</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353658</th>\n",
              "      <td>5533</td>\n",
              "      <td>1221</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135678</th>\n",
              "      <td>5533</td>\n",
              "      <td>1198</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49466</th>\n",
              "      <td>5533</td>\n",
              "      <td>260</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372121</th>\n",
              "      <td>5533</td>\n",
              "      <td>2442</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54682</th>\n",
              "      <td>5533</td>\n",
              "      <td>2028</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535785</th>\n",
              "      <td>5533</td>\n",
              "      <td>2453</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  ratings  rank  gender  age  occupation\n",
              "340043    5533      266        4     5       1   50           2\n",
              "516854    5533      969        5    18       1   50           2\n",
              "633356    5533     2173        4    12       1   50           2\n",
              "894409    5533     1913        5     2       1   50           2\n",
              "679053    5533     2019        5    18       1   50           2\n",
              "628529    5533     1185        5     5       1   50           2\n",
              "30936     5533     1097        4    12       1   50           2\n",
              "21527     5533     2797        4    12       1   50           2\n",
              "79302     5533     1217        5     8       1   50           2\n",
              "564107    5533     3101        2     1       1   50           2\n",
              "86814     5533      902        3     5       1   50           2\n",
              "205117    5533     1304        4    18       1   50           2\n",
              "630697    5533      247        4    12       1   50           2\n",
              "491029    5533      858        4     8       1   50           2\n",
              "353658    5533     1221        4     8       1   50           2\n",
              "135678    5533     1198        4    18       1   50           2\n",
              "49466     5533      260        5    12       1   50           2\n",
              "372121    5533     2442        4     2       1   50           2\n",
              "54682     5533     2028        3    18       1   50           2\n",
              "535785    5533     2453        2    12       1   50           2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bpmsG-WmPwU",
        "outputId": "9d4f59bf-0941-4de6-d290-e6e77141ac2b"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def make_predictions(user, n=10):\r\n",
        "  \"\"\"\r\n",
        "  Funtion to make top N recommendations to a given user\r\n",
        "  \"\"\"\r\n",
        "  # users's watched movies\r\n",
        "  watched_movies = dataset[dataset.userId == user]['movieId'].values\r\n",
        "\r\n",
        "  # construct samples matrix\r\n",
        "  samples = []\r\n",
        "  for movie in movie_ids:\r\n",
        "    sample = [user, movie, rank, occupation]\r\n",
        "    samples.append(sample)\r\n",
        "  samples = torch.tensor(samples)\r\n",
        "\r\n",
        "  # run the model for our samples\r\n",
        "  predictions = model(samples).detach().numpy()\r\n",
        "\r\n",
        "  normalized_predictions = [i/max(predictions)*5 for i in predictions]\r\n",
        "  normalized_predictions = {key:value for (key,value) in enumerate(normalized_predictions)}\r\n",
        "\r\n",
        "  # filter out movies the user haven't watched\r\n",
        "  unwatched_movies = {}\r\n",
        "  for i, movie in enumerate(movie_ids):\r\n",
        "    if movie not in watched_movies:\r\n",
        "      unwatched_movies[i] = movie\r\n",
        " \r\n",
        "  # get the indexes of top n ratings from sorted predictions\r\n",
        "  indexes = [idx for idx in sorted(normalized_predictions, key=normalized_predictions.get, reverse=True)][:n]\r\n",
        "  \r\n",
        "  # get the original movie indexes\r\n",
        "  recommendations = []\r\n",
        "  for idx in indexes:\r\n",
        "    recommendations.append(unwatched_movies.get(idx))\r\n",
        "\r\n",
        "  return recommendations\r\n",
        "\r\n",
        "user = 5533 # take userId == 5533 as an example\r\n",
        "rank = 1 + n_user + n_item\r\n",
        "occupation = dataset[dataset.userId == user]['occupation'].unique().item() + n_user + n_item + n_rank\r\n",
        "\r\n",
        "n = 10 # make 10 recommendations\r\n",
        "movie_ids = dataset['movieId'].unique()\r\n",
        "# run the function\r\n",
        "movies = make_predictions(user, n=10)\r\n",
        "\r\n",
        "# print out the recommended movies\r\n",
        "print(f'Top {n} recommended movie ids:')\r\n",
        "for idx in movies:\r\n",
        "  print(idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 recommended movie ids:\n",
            "2339\n",
            "283\n",
            "3324\n",
            "1021\n",
            "3902\n",
            "1349\n",
            "682\n",
            "953\n",
            "640\n",
            "1940\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}