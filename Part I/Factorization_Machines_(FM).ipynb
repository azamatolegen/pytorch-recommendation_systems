{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GitHub: Factorization Machines (FM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8IxcFFpGx1L"
      },
      "source": [
        "# Factorization Machines \n",
        "\n",
        "Factorization machines (FM) is a supervised algorithm that can be used for classification, regression, and ranking tasks. Particularly, it is a generalization of the linear regression model and the matrix factorization model. \n",
        "\n",
        "FM is formulated as a linear model, with interactions between features as additional parameters (features). However, these user/item indicators can be augmented with arbitrary auxiliary features, for example, user or item attributes and/or contextual features relevant to the interaction itself. These feature interactions are done in their latent space representation instead of their plain format.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1-1ywT0sOGrYs8lXJ-zljSrF2mF6gQxvS)\n",
        "\n",
        "* A linear model, given a vector *x* models its output *y* as: \n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1U1HUGuROvvxHQ-abyJHx5HgoQvd7ExDD)\n",
        "  \n",
        "  where *w* are the learnable weights of the model.\n",
        "\n",
        "  The drawback of this model is that it does not handle feature interactions. To capture interactions, we could introduce a weight *Wui* for each feature combination (that combines both user *u* and movie (item) *i* interaction).\n",
        "\n",
        "*  The resulting model for a factorization machine of degree two is defined as:\n",
        "![](https://drive.google.com/uc?id=1W_ndd8TORVF_3zFk40wNifBPZYtPP0jo)\n",
        "\n",
        "   Compared to our previous model, this formulation has the advantages that it can capture feature interactions at least for two features at a time. However, this introduces a large number of *w2* variables.\n",
        "\n",
        "* To solve this complexity issue, Factorization Machines takes inspiration from matrix factorization, and models the feature interaction using latent factors.Therefore previous equiation can be  re-formulation as low-rank re-formulation to reduce the number of additional parameters for the factorization machine.\n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1L9cx5gghNPaf_FpTCWj6EwhS6--FhAMg)\n",
        "\n",
        "  The first two terms correspond to the linear regression model and the last term is an extension of the matrix factorization model. If the feature *i*  represents an item and the feature *j*  represents a user, the third term is exactly the dot product between user and item embeddings. \n",
        "\n",
        "-------------------------------\n",
        "**Advantages:** We'll now wrap up the theoretical section of factorization machine, with some of its advantages:\n",
        "\n",
        "* We can observe from the model equation that it can be computed in linear time.\n",
        "* By leveraging ideas from matrix factorization, we can estimate higher order interaction effects even under very sparse data.\n",
        "* Compared to traditional matrix factorization methods, which is restricted to modeling a user-item matrix, we can leverage other user or item specific features making factorization machine more flexible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7palkAIRf4L9"
      },
      "source": [
        "# Model implementation in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wjfQ9PYy0E5"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "torch.manual_seed(2020)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX7GzwMFOZC8"
      },
      "source": [
        "# Initialize a Loader class\n",
        "class Loader():\n",
        "    # Set the iterator\n",
        "    current = 0\n",
        "\n",
        "    def __init__(self, x, y, batchsize=1024, do_shuffle=True):\n",
        "        \"\"\"\n",
        "        :param x: features\n",
        "        :param y: target\n",
        "        :param batchsize: batch size = 1024\n",
        "        :param do_shuffle: shuffle mode turned on\n",
        "        \"\"\"\n",
        "        self.shuffle = shuffle\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.batchsize = batchsize\n",
        "        self.batches = range(0, len(self.y), batchsize)\n",
        "        if do_shuffle:\n",
        "            # Every epoch re-shuffle the dataset\n",
        "            self.x, self.y = shuffle(self.x, self.y)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Reset & return a new iterator\n",
        "        self.x, self.y = shuffle(self.x, self.y, random_state=0)\n",
        "        self.current = 0\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of batches\n",
        "        return int(len(self.x) / self.batchsize)\n",
        "\n",
        "    def __next__(self):\n",
        "        # Update iterator and stop iteration until the batch size is out of range\n",
        "        n = self.batchsize\n",
        "        if self.current + n >= len(self.y):\n",
        "            raise StopIteration\n",
        "        i = self.current\n",
        "\n",
        "        # Transform NumPy arrays to PyTorch tensors\n",
        "        xs = torch.from_numpy(self.x[i:i + n])\n",
        "        ys = torch.from_numpy(self.y[i:i + n])\n",
        "        self.current += n\n",
        "        return xs, ys\n",
        "    \n",
        "def index_into(arr, idx):\n",
        "    # 2D array indexing\n",
        "    new_shape = (idx.size()[0], idx.size()[1], arr.size()[1])\n",
        "    return arr[idx.resize(torch.numel(idx.data))].view(new_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXU-FnjQgdoM"
      },
      "source": [
        "We can reorganize the third term of FM which could greatly reduce the computation cost, leading to a linear time complexity. The reformulation of the pairwise interaction term is as follows:\n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1_MElToR5G_6bDhv4S3nrZKS8KmT9Zc1c)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAlHOSWggb6"
      },
      "source": [
        "def factorization_machine(v, x=None):\n",
        "    \"\"\"\n",
        "    Takes an input 2D matrix v of n vectors, each d-dimensional\n",
        "    :param v: (batchsize, n_features, dim)\n",
        "    :param x: (batchsize, n_features) functions as a weight array, assumed to be 1 if missing\n",
        "    :return: output that is d-dimensional\n",
        "    \"\"\"\n",
        "    batchsize = v.size()[0]\n",
        "    n_features = v.size()[1]\n",
        "    n_dim = v.size()[2]\n",
        "\n",
        "    if x is None:\n",
        "        x = Variable(torch.ones(v.size()))\n",
        "    else:\n",
        "        x = x.expand(batchsize, n_features, n_dim)\n",
        "\n",
        "    # Uses Rendle's trick for computing pairs of features in linear time\n",
        "    square_of_sum  = (v * x).sum(dim=1) ** 2.0\n",
        "    sum_of_square  = (v ** 2.0 * x ** 2.0).sum(dim=1)\n",
        "    return 0.5 * (square_of_sum  - sum_of_square )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9pK5V9EOZO2"
      },
      "source": [
        "class FM(nn.Module):\n",
        "    \"\"\"\n",
        "    Factorization Machines model class\n",
        "    \"\"\"\n",
        "    # Iteration counter\n",
        "    itr = 0\n",
        "\n",
        "    def __init__(self, n_feat, k=10, c_feat=1.0, c_bias=1.0):\n",
        "        \"\"\"\n",
        "        :param n_feat: Feature column\n",
        "        :param k: Dimensions constant\n",
        "        :param c_feat: Regularization constant for the features\n",
        "        :param c_bias: Regularization constant for the biases\n",
        "        \"\"\"\n",
        "        super(FM, self).__init__()\n",
        "\n",
        "        # These are the hyper-parameters\n",
        "        self.k = k\n",
        "        self.n_feat = n_feat\n",
        "        self.c_feat = c_feat\n",
        "        self.c_bias = c_bias\n",
        "\n",
        "        # The embedding matrices for the features and the feature's biases\n",
        "        self.feat = nn.Embedding(n_feat, k)\n",
        "        self.bias_feat = nn.Embedding(n_feat, 1)\n",
        "\n",
        "    def __call__(self, train_x):\n",
        "        \"\"\"This is the most important function in this script\"\"\"\n",
        "        # Pull out biases\n",
        "        biases = index_into(self.bias_feat.weight, train_x).squeeze().sum(dim=1)\n",
        "\n",
        "        # Initialize vector features using the feature weights\n",
        "        vector_features = index_into(self.feat.weight, train_x)\n",
        "\n",
        "        # Use factorization machines to pull out the interactions\n",
        "        interactions = factorization_machine(vector_features).squeeze().sum(dim=1)\n",
        "\n",
        "        # Final prediction is the sum of biases and interactions\n",
        "        prediction = biases + interactions\n",
        "        return prediction\n",
        "\n",
        "    def loss(self, prediction, target):\n",
        "        \"\"\"\n",
        "        Function to calculate the loss metric\n",
        "        \"\"\"\n",
        "        # Calculate the Mean Squared Error between target and prediction\n",
        "        loss_mse = F.mse_loss(prediction.squeeze(), target.squeeze())\n",
        "\n",
        "        # Compute L2 regularization over feature matrices\n",
        "        prior_feat = l2_regularize(self.feat.weight) * self.c_feat\n",
        "\n",
        "        # Add the MSE loss and feature regularization to get total loss\n",
        "        total = (loss_mse + prior_feat)\n",
        "        \n",
        "        return total\n",
        "\n",
        "# FMs are prone to overfitting and for this reason L2 regularization is applied\n",
        "def l2_regularize(array):\n",
        "    \"\"\"\n",
        "    Function to do L2 regularization\n",
        "    \"\"\"\n",
        "    loss = torch.sum(array ** 2.0)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycxyv0vxg-BS",
        "outputId": "2a5efd91-1587-46b3-ab9c-0ac7b7eac5af"
      },
      "source": [
        "# get the data\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-08 07:36:34--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  12.8MB/s    in 0.4s    \n",
            "\n",
            "2021-05-08 07:36:35 (12.8 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "uHMVxycaOZRA",
        "outputId": "b07be177-12a2-4926-f3d8-5a75416fbb8a"
      },
      "source": [
        "# read the data\n",
        "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', engine='python', \n",
        "                      names=('userId', 'movieId','ratings','timestamp'))\n",
        "\n",
        "# Create users dataframe\n",
        "users = pd.read_csv(\"./ml-1m/users.dat\", sep='::', engine='python',\n",
        "                    names=['userId', 'gender', 'age', 'occupation', 'zipcode'])\n",
        "\n",
        "# Create users dataframe\n",
        "movies = pd.read_csv(\"./ml-1m/movies.dat\", sep='::', engine='python',\n",
        "                    names=['movieId', 'title', 'genres_str'])\n",
        "\n",
        "# Is this rating the first rating ever for that user, or the nth?\n",
        "ratings['rank'] = ratings.groupby(\"userId\")[\"timestamp\"].rank(ascending=True).astype('int64')\n",
        "\n",
        "# Merge ratings & user features\n",
        "dataset = ratings.merge(users, on='userId')\n",
        "dataset = dataset.merge(movies, on='movieId')\n",
        "dataset = dataset.sample(frac=1)\n",
        "dataset.drop(columns=['timestamp', 'zipcode', 'title', 'genres_str'], inplace=True)\n",
        "dataset['gender'] = dataset['gender'].map({'M':0, 'F':1})\n",
        "assert len(ratings) == len(dataset)\n",
        "\n",
        "# Compute cardinalities\n",
        "n_user = dataset.userId.max() + 1\n",
        "n_item = dataset.movieId.max() + 1\n",
        "n_rank = dataset['rank'].max() + 1\n",
        "n_age = dataset['age'].max() + 1\n",
        "n_occu = dataset['occupation'].max() + 1\n",
        "n_gen = dataset['gender'].nunique()\n",
        "# n_feat = n_user + n_item + n_rank + n_age + n_occu + n_gen\n",
        "n_feat = n_user + n_item + n_occu + n_rank\n",
        "\n",
        "print('n_user', n_user)\n",
        "print('n_item', n_item)\n",
        "print('n_rank', n_rank)\n",
        "print('n_gen', n_gen)\n",
        "print('n_age', n_age)\n",
        "print('n_occu', n_occu)\n",
        "print('n_feat', n_feat)\n",
        "print('n_rows', len(dataset))\n",
        "\n",
        "display(dataset.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_user 6041\n",
            "n_item 3953\n",
            "n_rank 2315\n",
            "n_gen 2\n",
            "n_age 57\n",
            "n_occu 21\n",
            "n_feat 12330\n",
            "n_rows 1000209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rank</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>283677</th>\n",
              "      <td>3756</td>\n",
              "      <td>1500</td>\n",
              "      <td>5</td>\n",
              "      <td>276</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231807</th>\n",
              "      <td>3507</td>\n",
              "      <td>1466</td>\n",
              "      <td>3</td>\n",
              "      <td>288</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537547</th>\n",
              "      <td>1340</td>\n",
              "      <td>1586</td>\n",
              "      <td>2</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916125</th>\n",
              "      <td>1265</td>\n",
              "      <td>3317</td>\n",
              "      <td>5</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12007</th>\n",
              "      <td>3518</td>\n",
              "      <td>919</td>\n",
              "      <td>5</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  ratings  rank  gender  age  occupation\n",
              "283677    3756     1500        5   276       0   18          12\n",
              "231807    3507     1466        3   288       0   25           0\n",
              "537547    1340     1586        2   254       0   25           7\n",
              "916125    1265     3317        5    57       1   18          20\n",
              "12007     3518      919        5   159       1   18           7"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vPCF1YwOZT7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# split the dataset into training and testing datasets\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.1, random_state=42, stratify=dataset.ratings)\n",
        "\n",
        "train_df.loc[:, 'movieId'] = n_user\n",
        "train_df.loc[:, 'rank'] = n_user + n_item\n",
        "train_df.loc[:, 'occupation'] = n_user + n_item + n_occu\n",
        "\n",
        "test_df.loc[:, 'movieId'] = n_user\n",
        "test_df.loc[:, 'rank'] = n_user + n_item\n",
        "test_df.loc[:, 'occupation'] = n_user + n_item + n_occu\n",
        "\n",
        "train_X = torch.tensor(train_df[['userId', 'movieId', 'rank', 'occupation']].values)\n",
        "train_y = torch.FloatTensor(train_df['ratings'].values)\n",
        "test_x = torch.tensor(test_df[['userId', 'movieId', 'rank', 'occupation']].values)\n",
        "test_y = torch.FloatTensor(test_df['ratings'].values)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(train_X, train_y), batch_size=1024)\n",
        "test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZsfaz-thnO_"
      },
      "source": [
        "# fit the model to the input data and label.\n",
        "def fit(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    # for epoch in range(epochs):\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        x, y = batch[0], batch[1]\n",
        "        y_pred = model(x)\n",
        "        loss = model.loss(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# evaluate the model on unseen data\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    for batch in dataloader:\n",
        "        with torch.no_grad():\n",
        "            x, y = batch[0], batch[1]\n",
        "            y_pred = model(x)\n",
        "            loss = model.loss(y_pred, y)\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeHaZCAwWyfd",
        "outputId": "038c0cb0-f3f9-448d-8b2a-5e48f8bcf403"
      },
      "source": [
        "# Define the Hyper-parameters\n",
        "lr = 1e-2  # Learning rate\n",
        "k = 10  # Number of dimensions per user and item\n",
        "c_bias = 1e-5  # Bias constant\n",
        "c_feat = 1e-5  # Regularization constant\n",
        "epochs = 10\n",
        "\n",
        "# Instantiate the model class object\n",
        "model = FM(n_feat, k=k, c_bias=c_bias, c_feat=c_feat)\n",
        "\n",
        "# Use Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Loop through pre-defined number of epochs\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Perform training on the train set\n",
        "    train_loss = fit(model, dataloader=train_loader, optimizer=optimizer)\n",
        "    print('epoch:', epoch, 'training loss:', train_loss)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Perform evaluation on the test set\n",
        "    test_loss = evaluate(model, test_loader)\n",
        "    print('epoch:', epoch, 'testing  loss:', test_loss)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'mf.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 training loss: 1.4483391046524048\n",
            "epoch: 0 testing  loss: 1.582596778869629\n",
            "epoch: 1 training loss: 1.3169660568237305\n",
            "epoch: 1 testing  loss: 1.457076072692871\n",
            "epoch: 2 training loss: 1.233760118484497\n",
            "epoch: 2 testing  loss: 1.3423691987991333\n",
            "epoch: 3 training loss: 1.165176510810852\n",
            "epoch: 3 testing  loss: 1.2605443000793457\n",
            "epoch: 4 training loss: 1.1163579225540161\n",
            "epoch: 4 testing  loss: 1.2099833488464355\n",
            "epoch: 5 training loss: 1.0783677101135254\n",
            "epoch: 5 testing  loss: 1.1765307188034058\n",
            "epoch: 6 training loss: 1.0634124279022217\n",
            "epoch: 6 testing  loss: 1.1540272235870361\n",
            "epoch: 7 training loss: 1.0428602695465088\n",
            "epoch: 7 testing  loss: 1.1454930305480957\n",
            "epoch: 8 training loss: 0.9895316362380981\n",
            "epoch: 8 testing  loss: 1.1386597156524658\n",
            "epoch: 9 training loss: 0.9562958478927612\n",
            "epoch: 9 testing  loss: 1.1311149597167969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "WHirNA8QhnVU",
        "outputId": "09610ee5-92b7-49e2-c67b-fa823d90fe2b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot( train_losses, 'b', label='Training loss')\n",
        "plt.plot( test_losses, 'r', label='Testing loss')\n",
        "plt.title('Training and Test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsQaITYdwA1"
      },
      "source": [
        "# Undertanding Model Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1iTnjPqty3w",
        "outputId": "34dbabfb-d173-48c8-d6ba-56460f019f12"
      },
      "source": [
        "# explore the features embedding matrix weights\n",
        "feat_weight = model.feat.weight\n",
        "print(feat_weight.size())\n",
        "print(feat_weight[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12330, 10])\n",
            "tensor([ 1.2774e-38, -4.4778e-40, -2.0292e-40, -6.5776e-38, -3.6661e-39,\n",
            "         3.7298e-39, -1.6310e-39,  8.6407e-40, -1.5546e-39,  1.6225e-39],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP_i-Kf8uWpH",
        "outputId": "8f28caea-31b0-4ce6-e365-af93a20e0f6f"
      },
      "source": [
        "# explore the biases embedding matrix weights\n",
        "bias_weight = model.bias_feat.weight\n",
        "print(bias_weight.size())\n",
        "print(bias_weight[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12330, 1])\n",
            "tensor([-0.7479], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKbGxysIngET",
        "outputId": "0538cf33-8053-4d45-c612-cc3a1b51e46d"
      },
      "source": [
        "# one batch of train loader looks like\n",
        "next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 3583,  6041,  9994, 10015],\n",
              "         [ 1354,  6041,  9994, 10015],\n",
              "         [ 4560,  6041,  9994, 10015],\n",
              "         ...,\n",
              "         [ 1680,  6041,  9994, 10015],\n",
              "         [  899,  6041,  9994, 10015],\n",
              "         [ 2425,  6041,  9994, 10015]]),\n",
              " tensor([5., 3., 4.,  ..., 4., 4., 4.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCdLjCqMtm0A",
        "outputId": "2e3b7585-0dcc-4b7a-fe40-2c0275548493"
      },
      "source": [
        "# get vector features using the index from 2-dimensonal (number of features, k-factor) feature weights matrix\n",
        "vector_features = index_into(feat_weight, train_X)\n",
        "print(len(vector_features))\n",
        "print(vector_features[0])\n",
        "print(vector_features.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "tensor([[ 0.0061, -0.1868,  0.2844,  0.0416,  0.0808,  0.0425, -0.1214,  0.0692,\n",
            "          0.1211,  0.2185],\n",
            "        [-0.3722,  0.1148,  0.0079, -0.0046,  0.1850,  0.0509, -0.0681,  0.0450,\n",
            "         -0.0321,  0.0420],\n",
            "        [ 0.1671,  0.3914, -0.0197, -0.0605,  0.1793, -0.0423, -0.0604,  0.1423,\n",
            "          0.0447,  0.0059],\n",
            "        [ 0.1717, -0.4642, -0.0124,  0.0579, -0.0053,  0.2227, -0.0792,  0.1508,\n",
            "         -0.1243,  0.0450]], grad_fn=<SelectBackward>)\n",
            "torch.Size([900188, 4, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BREv15DUvhkv",
        "outputId": "22d7baa0-f97d-4bc5-fca4-0ac06f317874"
      },
      "source": [
        "# compute interactions using usign Rendle's trick \n",
        "interactions = factorization_machine(vector_features).squeeze().sum(dim=1)\n",
        "print(len(interactions))\n",
        "print(interactions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "tensor([-0.1326, -0.5858, -0.2065,  ..., -0.4025, -0.2453, -0.2591],\n",
            "       grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9vL-kcSvmLk",
        "outputId": "e5801e95-9f48-471c-bbf8-def82c12be8c"
      },
      "source": [
        "# get baiases from bias weights matrix\n",
        "biases = index_into(bias_weight, train_X).squeeze().sum(dim=1)\n",
        "print(len(biases))\n",
        "print(biases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "900188\n",
            "tensor([4.3350, 3.9201, 3.7164,  ..., 4.4235, 3.9204, 4.1202],\n",
            "       grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whdHQ6B_v3oq",
        "outputId": "2a16064a-1fe4-4891-a32c-5fa76917ca5f"
      },
      "source": [
        "# compute final predictions by summing bias and interaction\n",
        "prediction = biases + interactions\n",
        "print(prediction.detach())\n",
        "print(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4.2024, 3.3343, 3.5098,  ..., 4.0210, 3.6751, 3.8611])\n",
            "tensor([5., 3., 4.,  ..., 4., 5., 5.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBmxUDklVh9"
      },
      "source": [
        "We can see that the model reconstructs original ratings nor that well. Things we can try to improve that:\n",
        "\n",
        "* Get more data\n",
        "* Tune hyper-patameters (especially k-factor)\n",
        "* Train the model for more epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd_SyyDpdxCk"
      },
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "yNhMQzkK58yj",
        "outputId": "a0df5a75-7bb8-482b-c5c3-706fc2f60858"
      },
      "source": [
        "dataset[dataset.userId == 5533]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rank</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>633356</th>\n",
              "      <td>5533</td>\n",
              "      <td>2173</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79302</th>\n",
              "      <td>5533</td>\n",
              "      <td>1217</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135678</th>\n",
              "      <td>5533</td>\n",
              "      <td>1198</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372121</th>\n",
              "      <td>5533</td>\n",
              "      <td>2442</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86814</th>\n",
              "      <td>5533</td>\n",
              "      <td>902</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49466</th>\n",
              "      <td>5533</td>\n",
              "      <td>260</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535785</th>\n",
              "      <td>5533</td>\n",
              "      <td>2453</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491029</th>\n",
              "      <td>5533</td>\n",
              "      <td>858</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628529</th>\n",
              "      <td>5533</td>\n",
              "      <td>1185</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564107</th>\n",
              "      <td>5533</td>\n",
              "      <td>3101</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205117</th>\n",
              "      <td>5533</td>\n",
              "      <td>1304</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340043</th>\n",
              "      <td>5533</td>\n",
              "      <td>266</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54682</th>\n",
              "      <td>5533</td>\n",
              "      <td>2028</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30936</th>\n",
              "      <td>5533</td>\n",
              "      <td>1097</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630697</th>\n",
              "      <td>5533</td>\n",
              "      <td>247</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353658</th>\n",
              "      <td>5533</td>\n",
              "      <td>1221</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21527</th>\n",
              "      <td>5533</td>\n",
              "      <td>2797</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679053</th>\n",
              "      <td>5533</td>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516854</th>\n",
              "      <td>5533</td>\n",
              "      <td>969</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894409</th>\n",
              "      <td>5533</td>\n",
              "      <td>1913</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  ratings  rank  gender  age  occupation\n",
              "633356    5533     2173        4    12       1   50           2\n",
              "79302     5533     1217        5     8       1   50           2\n",
              "135678    5533     1198        4    18       1   50           2\n",
              "372121    5533     2442        4     2       1   50           2\n",
              "86814     5533      902        3     5       1   50           2\n",
              "49466     5533      260        5    12       1   50           2\n",
              "535785    5533     2453        2    12       1   50           2\n",
              "491029    5533      858        4     8       1   50           2\n",
              "628529    5533     1185        5     5       1   50           2\n",
              "564107    5533     3101        2     1       1   50           2\n",
              "205117    5533     1304        4    18       1   50           2\n",
              "340043    5533      266        4     5       1   50           2\n",
              "54682     5533     2028        3    18       1   50           2\n",
              "30936     5533     1097        4    12       1   50           2\n",
              "630697    5533      247        4    12       1   50           2\n",
              "353658    5533     1221        4     8       1   50           2\n",
              "21527     5533     2797        4    12       1   50           2\n",
              "679053    5533     2019        5    18       1   50           2\n",
              "516854    5533      969        5    18       1   50           2\n",
              "894409    5533     1913        5     2       1   50           2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bpmsG-WmPwU",
        "outputId": "dfdfeb6d-158c-4269-e00e-fb9fc3c00f43"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_predictions(user, n=10):\n",
        "  \"\"\"\n",
        "  Funtion to make top N recommendations to a given user\n",
        "  \"\"\"\n",
        "  # users's watched movies\n",
        "  watched_movies = dataset[dataset.userId == user]['movieId'].values\n",
        "\n",
        "  # construct samples matrix\n",
        "  samples = []\n",
        "  for movie in movie_ids:\n",
        "    sample = [user, movie, rank, occupation]\n",
        "    samples.append(sample)\n",
        "  samples = torch.tensor(samples)\n",
        "\n",
        "  # run the model for our samples\n",
        "  predictions = model(samples).detach().numpy()\n",
        "\n",
        "  normalized_predictions = [i/max(predictions)*5 for i in predictions]\n",
        "  normalized_predictions = {key:value for (key,value) in enumerate(normalized_predictions)}\n",
        "\n",
        "  # filter out movies the user haven't watched\n",
        "  unwatched_movies = {}\n",
        "  for i, movie in enumerate(movie_ids):\n",
        "    if movie not in watched_movies:\n",
        "      unwatched_movies[i] = movie\n",
        " \n",
        "  # get the indexes of top n ratings from sorted predictions\n",
        "  indexes = [idx for idx in sorted(normalized_predictions, key=normalized_predictions.get, reverse=True)][:n]\n",
        "  \n",
        "  # get the original movie indexes\n",
        "  recommendations = []\n",
        "  for idx in indexes:\n",
        "    recommendations.append(unwatched_movies.get(idx))\n",
        "\n",
        "  return recommendations\n",
        "\n",
        "user = 5533 # take userId == 5533 as an example\n",
        "rank = 1 + n_user + n_item\n",
        "occupation = dataset[dataset.userId == user]['occupation'].unique().item() + n_user + n_item + n_rank\n",
        "\n",
        "n = 10 # make 10 recommendations\n",
        "movie_ids = dataset['movieId'].unique()\n",
        "# run the function\n",
        "movies = make_predictions(user, n=10)\n",
        "\n",
        "# print out the recommended movies\n",
        "print(f'Top {n} recommended movie ids:')\n",
        "for idx in movies:\n",
        "  print(idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 recommended movie ids:\n",
            "1021\n",
            "1635\n",
            "2339\n",
            "283\n",
            "3902\n",
            "1591\n",
            "953\n",
            "446\n",
            "3414\n",
            "3324\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}