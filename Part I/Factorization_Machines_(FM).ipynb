{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[GitHub] Factorization Machines (FM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8IxcFFpGx1L"
      },
      "source": [
        "# Factorization Machines \n",
        "\n",
        "Factorization machines (FM) is a supervised algorithm that can be used for classification, regression, and ranking tasks. Particularly, it is a generalization of the linear regression model and the matrix factorization model. \n",
        "\n",
        "FM is formulated as a linear model, with interactions between features as additional parameters (features). However, these user/item indicators can be augmented with arbitrary auxiliary features, for example, user or item attributes and/or contextual features relevant to the interaction itself. These feature interactions are done in their latent space representation instead of their plain format.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1-1ywT0sOGrYs8lXJ-zljSrF2mF6gQxvS)\n",
        "\n",
        "* A linear model, given a vector *x* models its output *y* as: \n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1U1HUGuROvvxHQ-abyJHx5HgoQvd7ExDD)\n",
        "  \n",
        "  where *w* are the learnable weights of the model.\n",
        "\n",
        "  The drawback of this model is that it does not handle feature interactions. To capture interactions, we could introduce a weight *Wui* for each feature combination (that combines both user *u* and movie (item) *i* interaction).\n",
        "\n",
        "*  The resulting model for a factorization machine of degree two is defined as:\n",
        "![](https://drive.google.com/uc?id=1W_ndd8TORVF_3zFk40wNifBPZYtPP0jo)\n",
        "\n",
        "   Compared to our previous model, this formulation has the advantages that it can capture feature interactions at least for two features at a time. However, this introduces a large number of *w2* variables.\n",
        "\n",
        "* To solve this complexity issue, Factorization Machines takes inspiration from matrix factorization, and models the feature interaction using latent factors.Therefore previous equiation can be  re-formulation as low-rank re-formulation to reduce the number of additional parameters for the factorization machine.\n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1L9cx5gghNPaf_FpTCWj6EwhS6--FhAMg)\n",
        "\n",
        "  The first two terms correspond to the linear regression model and the last term is an extension of the matrix factorization model. If the feature *i*  represents an item and the feature *j*  represents a user, the third term is exactly the dot product between user and item embeddings. \n",
        "\n",
        "-------------------------------\n",
        "**Advantages:** We'll now wrap up the theoretical section of factorization machine, with some of its advantages:\n",
        "\n",
        "* We can observe from the model equation that it can be computed in linear time.\n",
        "* By leveraging ideas from matrix factorization, we can estimate higher order interaction effects even under very sparse data.\n",
        "* Compared to traditional matrix factorization methods, which is restricted to modeling a user-item matrix, we can leverage other user or item specific features making factorization machine more flexible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7palkAIRf4L9"
      },
      "source": [
        "# Model implementation in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wjfQ9PYy0E5"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "torch.manual_seed(2020)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX7GzwMFOZC8"
      },
      "source": [
        "# Initialize a Loader class\n",
        "class Loader():\n",
        "    # Set the iterator\n",
        "    current = 0\n",
        "\n",
        "    def __init__(self, x, y, batchsize=1024, do_shuffle=True):\n",
        "        \"\"\"\n",
        "        :param x: features\n",
        "        :param y: target\n",
        "        :param batchsize: batch size = 1024\n",
        "        :param do_shuffle: shuffle mode turned on\n",
        "        \"\"\"\n",
        "        self.shuffle = shuffle\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.batchsize = batchsize\n",
        "        self.batches = range(0, len(self.y), batchsize)\n",
        "        if do_shuffle:\n",
        "            # Every epoch re-shuffle the dataset\n",
        "            self.x, self.y = shuffle(self.x, self.y)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Reset & return a new iterator\n",
        "        self.x, self.y = shuffle(self.x, self.y, random_state=0)\n",
        "        self.current = 0\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of batches\n",
        "        return int(len(self.x) / self.batchsize)\n",
        "\n",
        "    def __next__(self):\n",
        "        # Update iterator and stop iteration until the batch size is out of range\n",
        "        n = self.batchsize\n",
        "        if self.current + n >= len(self.y):\n",
        "            raise StopIteration\n",
        "        i = self.current\n",
        "\n",
        "        # Transform NumPy arrays to PyTorch tensors\n",
        "        xs = torch.from_numpy(self.x[i:i + n])\n",
        "        ys = torch.from_numpy(self.y[i:i + n])\n",
        "        self.current += n\n",
        "        return xs, ys\n",
        "    \n",
        "def index_into(arr, idx):\n",
        "    # 2D array indexing\n",
        "    new_shape = (idx.size()[0], idx.size()[1], arr.size()[1])\n",
        "    return arr[idx.resize(torch.numel(idx.data))].view(new_shape)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXU-FnjQgdoM"
      },
      "source": [
        "We can reorganize the third term of FM which could greatly reduce the computation cost, leading to a linear time complexity. The reformulation of the pairwise interaction term is as follows:\n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1_MElToR5G_6bDhv4S3nrZKS8KmT9Zc1c)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAlHOSWggb6"
      },
      "source": [
        "def factorization_machine(v, x=None):\n",
        "    \"\"\"\n",
        "    Takes an input 2D matrix v of n vectors, each d-dimensional\n",
        "    :param v: (batchsize, n_features, dim)\n",
        "    :param x: (batchsize, n_features) functions as a weight array, assumed to be 1 if missing\n",
        "    :return: output that is d-dimensional\n",
        "    \"\"\"\n",
        "    batchsize = v.size()[0]\n",
        "    n_features = v.size()[1]\n",
        "    n_dim = v.size()[2]\n",
        "\n",
        "    if x is None:\n",
        "        x = Variable(torch.ones(v.size()))\n",
        "    else:\n",
        "        x = x.expand(batchsize, n_features, n_dim)\n",
        "\n",
        "    # Uses Rendle's trick for computing pairs of features in linear time\n",
        "    square_of_sum  = (v * x).sum(dim=1) ** 2.0\n",
        "    sum_of_square  = (v ** 2.0 * x ** 2.0).sum(dim=1)\n",
        "    return 0.5 * (square_of_sum  - sum_of_square )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9pK5V9EOZO2"
      },
      "source": [
        "class FM(nn.Module):\n",
        "    \"\"\"\n",
        "    Factorization Machines model class\n",
        "    \"\"\"\n",
        "    # Iteration counter\n",
        "    itr = 0\n",
        "\n",
        "    def __init__(self, n_feat, k=10, c_feat=1.0, c_bias=1.0):\n",
        "        \"\"\"\n",
        "        :param n_feat: Feature column\n",
        "        :param k: Dimensions constant\n",
        "        :param c_feat: Regularization constant for the features\n",
        "        :param c_bias: Regularization constant for the biases\n",
        "        \"\"\"\n",
        "        super(FM, self).__init__()\n",
        "\n",
        "        # These are the hyper-parameters\n",
        "        self.k = k\n",
        "        self.n_feat = n_feat\n",
        "        self.c_feat = c_feat\n",
        "        self.c_bias = c_bias\n",
        "\n",
        "        # The embedding matrices for the features and the feature's biases\n",
        "        self.feat = nn.Embedding(n_feat, k)\n",
        "        self.bias_feat = nn.Embedding(n_feat, 1)\n",
        "\n",
        "    def __call__(self, train_x):\n",
        "        \"\"\"This is the most important function in this script\"\"\"\n",
        "        # Pull out biases\n",
        "        biases = index_into(self.bias_feat.weight, train_x).squeeze().sum(dim=1)\n",
        "\n",
        "        # Initialize vector features using the feature weights\n",
        "        vector_features = index_into(self.feat.weight, train_x)\n",
        "\n",
        "        # Use factorization machines to pull out the interactions\n",
        "        interactions = factorization_machine(vector_features).squeeze().sum(dim=1)\n",
        "\n",
        "        # Final prediction is the sum of biases and interactions\n",
        "        prediction = biases + interactions\n",
        "        return prediction\n",
        "\n",
        "    def loss(self, prediction, target):\n",
        "        \"\"\"\n",
        "        Function to calculate the loss metric\n",
        "        \"\"\"\n",
        "        # Calculate the Mean Squared Error between target and prediction\n",
        "        loss_mse = F.mse_loss(prediction.squeeze(), target.squeeze())\n",
        "\n",
        "        # Compute L2 regularization over feature matrices\n",
        "        prior_feat = l2_regularize(self.feat.weight) * self.c_feat\n",
        "\n",
        "        # Add the MSE loss and feature regularization to get total loss\n",
        "        total = (loss_mse + prior_feat)\n",
        "        \n",
        "        return total\n",
        "\n",
        "# FMs are prone to overfitting and for this reason L2 regularization is applied\n",
        "def l2_regularize(array):\n",
        "    \"\"\"\n",
        "    Function to do L2 regularization\n",
        "    \"\"\"\n",
        "    loss = torch.sum(array ** 2.0)\n",
        "    return loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycxyv0vxg-BS",
        "outputId": "5420afed-60e5-4148-8172-e178f98d8a9d"
      },
      "source": [
        "# get the data\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-08-31 09:26:13--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  29.6MB/s    in 0.2s    \n",
            "\n",
            "2021-08-31 09:26:14 (29.6 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "uHMVxycaOZRA",
        "outputId": "df4afccc-b174-40f0-8c00-73e02bd29b05"
      },
      "source": [
        "# read the data\n",
        "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', engine='python', names=('userId', 'movieId','ratings','timestamp'))\n",
        "\n",
        "# Create users dataframe\n",
        "users = pd.read_csv(\"./ml-1m/users.dat\", sep='::', engine='python', names=['userId', 'gender', 'age', 'occupation', 'zipcode'])\n",
        "\n",
        "# Create users dataframe\n",
        "movies = pd.read_csv(\"./ml-1m/movies.dat\", sep='::', engine='python', names=['movieId', 'title', 'genres_str'])\n",
        "\n",
        "# Is this rating the first rating ever for that user, or the nth?\n",
        "ratings['rank'] = ratings.groupby(\"userId\")[\"timestamp\"].rank(ascending=True).astype('int64')\n",
        "\n",
        "# Merge ratings & user features\n",
        "dataset = ratings.merge(users, on='userId')\n",
        "dataset = dataset.merge(movies, on='movieId')\n",
        "dataset = dataset.sample(frac=1)\n",
        "dataset.drop(columns=['timestamp', 'zipcode', 'title', 'genres_str'], inplace=True)\n",
        "dataset['gender'] = dataset['gender'].map({'M':0, 'F':1})\n",
        "assert len(ratings) == len(dataset)\n",
        "\n",
        "# Compute cardinalities\n",
        "n_user = dataset.userId.max() + 1\n",
        "n_item = dataset.movieId.max() + 1\n",
        "n_rank = dataset['rank'].max() + 1\n",
        "n_age = dataset['age'].max() + 1\n",
        "n_occu = dataset['occupation'].max() + 1\n",
        "n_gen = dataset['gender'].nunique()\n",
        "# n_feat = n_user + n_item + n_rank + n_age + n_occu + n_gen\n",
        "n_feat = n_user + n_item + n_occu + n_rank\n",
        "\n",
        "print('n_user', n_user)\n",
        "print('n_item', n_item)\n",
        "print('n_rank', n_rank)\n",
        "print('n_gen', n_gen)\n",
        "print('n_age', n_age)\n",
        "print('n_occu', n_occu)\n",
        "print('n_feat', n_feat)\n",
        "print('n_rows', len(dataset))\n",
        "\n",
        "display(dataset.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_user 6041\n",
            "n_item 3953\n",
            "n_rank 2315\n",
            "n_gen 2\n",
            "n_age 57\n",
            "n_occu 21\n",
            "n_feat 12330\n",
            "n_rows 1000209\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rank</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51418</th>\n",
              "      <td>564</td>\n",
              "      <td>1207</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252092</th>\n",
              "      <td>5848</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>324</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786551</th>\n",
              "      <td>1978</td>\n",
              "      <td>609</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487045</th>\n",
              "      <td>5287</td>\n",
              "      <td>3703</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670138</th>\n",
              "      <td>5048</td>\n",
              "      <td>3635</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  ratings  rank  gender  age  occupation\n",
              "51418      564     1207        5    15       0   45           1\n",
              "252092    5848       50        3   324       0   50          20\n",
              "786551    1978      609        3     3       0    1          10\n",
              "487045    5287     3703        4    36       0   25           8\n",
              "670138    5048     3635        3    10       1   35           7"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vPCF1YwOZT7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# split the dataset into training and testing datasets\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.1, random_state=42, stratify=dataset.ratings)\n",
        "\n",
        "train_df.loc[:, 'movieId'] = train_df.loc[:, 'movieId'] + n_user - 1\n",
        "train_df.loc[:, 'rank'] = train_df.loc[:, 'rank'] + n_user + n_item - 2\n",
        "train_df.loc[:, 'occupation'] = train_df.loc[:, 'occupation'] + n_user + n_item + n_rank - 3\n",
        "\n",
        "test_df.loc[:, 'movieId'] = test_df.loc[:, 'movieId'] + n_user - 1\n",
        "test_df.loc[:, 'rank'] = test_df.loc[:, 'rank'] + n_user + n_item - 2\n",
        "test_df.loc[:, 'occupation'] = test_df.loc[:, 'occupation'] + n_user + n_item + n_rank - 3\n",
        "\n",
        "train_X = torch.tensor(train_df[['userId', 'movieId', 'rank', 'occupation']].values)\n",
        "train_y = torch.FloatTensor(train_df['ratings'].values)\n",
        "test_x = torch.tensor(test_df[['userId', 'movieId', 'rank', 'occupation']].values)\n",
        "test_y = torch.FloatTensor(test_df['ratings'].values)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(train_X, train_y), batch_size=1024)\n",
        "test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=1024)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZsfaz-thnO_"
      },
      "source": [
        "# fit the model to the input data and label.\n",
        "def fit(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    # for epoch in range(epochs):\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        x, y = batch[0], batch[1]\n",
        "        y_pred = model(x)\n",
        "        loss = model.loss(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# evaluate the model on unseen data\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    for batch in dataloader:\n",
        "        with torch.no_grad():\n",
        "            x, y = batch[0], batch[1]\n",
        "            y_pred = model(x)\n",
        "            loss = model.loss(y_pred, y)\n",
        "    return loss.item()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeHaZCAwWyfd",
        "outputId": "5e1db876-f805-4e1c-d90c-293c003d4a4b"
      },
      "source": [
        "# Define the Hyper-parameters\n",
        "lr = 1e-2  # Learning rate\n",
        "k = 10  # Number of dimensions per user and item\n",
        "c_bias = 1e-5  # Bias constant\n",
        "c_feat = 1e-5  # Regularization constant\n",
        "epochs = 10\n",
        "\n",
        "# Instantiate the model class object\n",
        "model = FM(n_feat, k=k, c_bias=c_bias, c_feat=c_feat)\n",
        "\n",
        "# Use Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Loop through pre-defined number of epochs\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Perform training on the train set\n",
        "    train_loss = fit(model, dataloader=train_loader, optimizer=optimizer)\n",
        "    print('epoch:', epoch, 'training loss:', train_loss)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Perform evaluation on the test set\n",
        "    test_loss = evaluate(model, test_loader)\n",
        "    print('epoch:', epoch, 'testing  loss:', test_loss)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'mf.pt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 training loss: 2.4446353912353516\n",
            "epoch: 0 testing  loss: 2.3055500984191895\n",
            "epoch: 1 training loss: 0.9909727573394775\n",
            "epoch: 1 testing  loss: 1.2814478874206543\n",
            "epoch: 2 training loss: 0.8524733781814575\n",
            "epoch: 2 testing  loss: 1.0710121393203735\n",
            "epoch: 3 training loss: 0.7751405239105225\n",
            "epoch: 3 testing  loss: 0.9822860360145569\n",
            "epoch: 4 training loss: 0.7207872867584229\n",
            "epoch: 4 testing  loss: 0.9182935357093811\n",
            "epoch: 5 training loss: 0.7187595963478088\n",
            "epoch: 5 testing  loss: 0.8716986179351807\n",
            "epoch: 6 training loss: 0.6828450560569763\n",
            "epoch: 6 testing  loss: 0.8555312752723694\n",
            "epoch: 7 training loss: 0.6469877362251282\n",
            "epoch: 7 testing  loss: 0.8636407256126404\n",
            "epoch: 8 training loss: 0.6267709136009216\n",
            "epoch: 8 testing  loss: 0.8690025806427002\n",
            "epoch: 9 training loss: 0.6135601997375488\n",
            "epoch: 9 testing  loss: 0.8690454959869385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "WHirNA8QhnVU",
        "outputId": "c3ad8220-c3e5-4c93-b28d-13cedf6182c1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot( train_losses, 'b', label='Training loss')\n",
        "plt.plot( test_losses, 'r', label='Testing loss')\n",
        "plt.title('Training and Test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsQaITYdwA1"
      },
      "source": [
        "# Undertanding Model Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1iTnjPqty3w",
        "outputId": "52c62c8f-b650-4f2f-819d-4844720d4f2e"
      },
      "source": [
        "# explore the features embedding matrix weights\n",
        "feat_weight = model.feat.weight\n",
        "print(feat_weight.size())\n",
        "print(feat_weight[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12330, 10])\n",
            "tensor([ 1.2774e-38, -4.4778e-40, -2.0292e-40, -6.5776e-38, -3.6661e-39,\n",
            "         3.7298e-39, -1.6310e-39,  8.6407e-40, -1.5546e-39,  1.6225e-39],\n",
            "       grad_fn=<SelectBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP_i-Kf8uWpH",
        "outputId": "95909385-135c-434f-f0ec-7af28521b105"
      },
      "source": [
        "# explore the biases embedding matrix weights\n",
        "bias_weight = model.bias_feat.weight\n",
        "print(bias_weight.size())\n",
        "print(bias_weight[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12330, 1])\n",
            "tensor([-0.7479], grad_fn=<SelectBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKbGxysIngET",
        "outputId": "4ad456a2-864d-4015-e56a-acf6ad678f9b"
      },
      "source": [
        "# one batch of train loader looks like\n",
        "next(iter(train_loader))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 3191,  6627, 10244, 12318],\n",
              "         [ 4973,  9113, 10108, 12308],\n",
              "         [ 1950,  7431, 10030, 12318],\n",
              "         ...,\n",
              "         [ 3345,  9403, 10021, 12313],\n",
              "         [ 3526,  7993, 10588, 12308],\n",
              "         [ 5306,  8129, 10223, 12323]]),\n",
              " tensor([5., 3., 4.,  ..., 4., 4., 4.])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCdLjCqMtm0A",
        "outputId": "c780a0b2-6e7a-4e10-c670-c1f9c200f3bf"
      },
      "source": [
        "# get vector features using the index from 2-dimensonal (number of features, k-factor) feature weights matrix\n",
        "vector_features = index_into(feat_weight, train_X)\n",
        "print(len(vector_features))\n",
        "print(vector_features[0])\n",
        "print(vector_features.size())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900188\n",
            "tensor([[-0.0388,  0.1005,  0.0890,  0.0713,  0.1999, -0.0274,  0.4738,  0.0937,\n",
            "          0.3804, -0.3489],\n",
            "        [ 0.3164,  0.9788,  0.1159, -0.1089, -0.1467,  0.1934, -0.1138,  0.3784,\n",
            "         -0.0131, -0.7459],\n",
            "        [ 0.1862,  0.0786,  0.1279, -0.0417,  0.2084, -0.0909,  0.0780, -0.0385,\n",
            "         -0.0795,  0.0134],\n",
            "        [-0.0483,  0.0544,  0.0186,  0.0017, -0.0850,  0.0189,  0.0341, -0.0486,\n",
            "         -0.0106,  0.0574]], grad_fn=<SelectBackward>)\n",
            "torch.Size([900188, 4, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BREv15DUvhkv",
        "outputId": "633c59b0-eb21-4df0-94d4-7bae02246648"
      },
      "source": [
        "# compute interactions using usign Rendle's trick \n",
        "interactions = factorization_machine(vector_features).squeeze().sum(dim=1)\n",
        "print(len(interactions))\n",
        "print(interactions)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900188\n",
            "tensor([ 0.3719,  0.0140, -0.1061,  ...,  0.1586,  0.5374,  0.8604],\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9vL-kcSvmLk",
        "outputId": "64c83935-d3ab-4d4a-dbe3-e18179f1fad7"
      },
      "source": [
        "# get baiases from bias weights matrix\n",
        "biases = index_into(bias_weight, train_X).squeeze().sum(dim=1)\n",
        "print(len(biases))\n",
        "print(biases)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900188\n",
            "tensor([3.4634, 2.9233, 3.0283,  ..., 3.7219, 4.1200, 3.6828],\n",
            "       grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whdHQ6B_v3oq",
        "outputId": "e47d7529-1261-41b4-b86f-4a6d6006d6f8"
      },
      "source": [
        "# compute final predictions by summing bias and interaction\n",
        "prediction = biases + interactions\n",
        "print(prediction.detach()[:10])\n",
        "print(train_y[:10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.8353, 2.9372, 2.9222, 3.6963, 3.6009, 3.6175, 2.9777, 2.6884, 4.2625,\n",
            "        3.1748])\n",
            "tensor([5., 3., 4., 4., 4., 4., 4., 3., 4., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBmxUDklVh9"
      },
      "source": [
        "We can see that the model reconstructs original ratings nor that well. Things we can try to improve that:\n",
        "\n",
        "* Get more data\n",
        "* Tune hyper-patameters (especially k-factor)\n",
        "* Train the model for more epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd_SyyDpdxCk"
      },
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "yNhMQzkK58yj",
        "outputId": "a274304f-f4fa-443c-be9c-36be9f5caaf5"
      },
      "source": [
        "dataset[dataset.userId == 5533]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rank</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>535785</th>\n",
              "      <td>5533</td>\n",
              "      <td>2453</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630697</th>\n",
              "      <td>5533</td>\n",
              "      <td>247</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491029</th>\n",
              "      <td>5533</td>\n",
              "      <td>858</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372121</th>\n",
              "      <td>5533</td>\n",
              "      <td>2442</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353658</th>\n",
              "      <td>5533</td>\n",
              "      <td>1221</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894409</th>\n",
              "      <td>5533</td>\n",
              "      <td>1913</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49466</th>\n",
              "      <td>5533</td>\n",
              "      <td>260</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679053</th>\n",
              "      <td>5533</td>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516854</th>\n",
              "      <td>5533</td>\n",
              "      <td>969</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340043</th>\n",
              "      <td>5533</td>\n",
              "      <td>266</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633356</th>\n",
              "      <td>5533</td>\n",
              "      <td>2173</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54682</th>\n",
              "      <td>5533</td>\n",
              "      <td>2028</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628529</th>\n",
              "      <td>5533</td>\n",
              "      <td>1185</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564107</th>\n",
              "      <td>5533</td>\n",
              "      <td>3101</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79302</th>\n",
              "      <td>5533</td>\n",
              "      <td>1217</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30936</th>\n",
              "      <td>5533</td>\n",
              "      <td>1097</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21527</th>\n",
              "      <td>5533</td>\n",
              "      <td>2797</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135678</th>\n",
              "      <td>5533</td>\n",
              "      <td>1198</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86814</th>\n",
              "      <td>5533</td>\n",
              "      <td>902</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205117</th>\n",
              "      <td>5533</td>\n",
              "      <td>1304</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  ratings  rank  gender  age  occupation\n",
              "535785    5533     2453        2    12       1   50           2\n",
              "630697    5533      247        4    12       1   50           2\n",
              "491029    5533      858        4     8       1   50           2\n",
              "372121    5533     2442        4     2       1   50           2\n",
              "353658    5533     1221        4     8       1   50           2\n",
              "894409    5533     1913        5     2       1   50           2\n",
              "49466     5533      260        5    12       1   50           2\n",
              "679053    5533     2019        5    18       1   50           2\n",
              "516854    5533      969        5    18       1   50           2\n",
              "340043    5533      266        4     5       1   50           2\n",
              "633356    5533     2173        4    12       1   50           2\n",
              "54682     5533     2028        3    18       1   50           2\n",
              "628529    5533     1185        5     5       1   50           2\n",
              "564107    5533     3101        2     1       1   50           2\n",
              "79302     5533     1217        5     8       1   50           2\n",
              "30936     5533     1097        4    12       1   50           2\n",
              "21527     5533     2797        4    12       1   50           2\n",
              "135678    5533     1198        4    18       1   50           2\n",
              "86814     5533      902        3     5       1   50           2\n",
              "205117    5533     1304        4    18       1   50           2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bpmsG-WmPwU",
        "outputId": "9df9596c-4ea1-40ee-f9d7-11113e1a796d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_predictions(user, n=10):\n",
        "  \"\"\"\n",
        "  Funtion to make top N recommendations to a given user\n",
        "  \"\"\"\n",
        "  # users's watched movies\n",
        "  watched_movies = dataset[dataset.userId == user]['movieId'].values\n",
        "\n",
        "  # construct samples matrix\n",
        "  samples = []\n",
        "  for movie in movie_ids:\n",
        "    sample = [user, movie, rank, occupation]\n",
        "    samples.append(sample)\n",
        "  samples = torch.tensor(samples)\n",
        "\n",
        "  # run the model for our samples\n",
        "  predictions = model(samples).detach().numpy()\n",
        "\n",
        "  normalized_predictions = [i/max(predictions)*5 for i in predictions]\n",
        "  normalized_predictions = {key:value for (key,value) in enumerate(normalized_predictions)}\n",
        "\n",
        "  # filter out movies the user haven't watched\n",
        "  unwatched_movies = {}\n",
        "  for i, movie in enumerate(movie_ids):\n",
        "    if movie not in watched_movies:\n",
        "      unwatched_movies[i] = movie\n",
        " \n",
        "  # get the indexes of top n ratings from sorted predictions\n",
        "  indexes = [idx for idx in sorted(normalized_predictions, key=normalized_predictions.get, reverse=True)][:n]\n",
        "  \n",
        "  # get the original movie indexes\n",
        "  recommendations = []\n",
        "  for idx in indexes:\n",
        "    recommendations.append(unwatched_movies.get(idx))\n",
        "\n",
        "  return recommendations\n",
        "\n",
        "user = 5533 # take userId == 5533 as an example\n",
        "rank = 1 + n_user + n_item\n",
        "occupation = dataset[dataset.userId == user]['occupation'].unique().item() + n_user + n_item + n_rank\n",
        "\n",
        "n = 10 # make 10 recommendations\n",
        "movie_ids = dataset['movieId'].unique()\n",
        "# run the function\n",
        "movies = make_predictions(user, n=10)\n",
        "\n",
        "# print out the recommended movies\n",
        "print(f'Top {n} recommended movie ids:')\n",
        "for idx in movies:\n",
        "  print(idx)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 recommended movie ids:\n",
            "3902\n",
            "597\n",
            "1171\n",
            "2852\n",
            "3801\n",
            "1940\n",
            "567\n",
            "1132\n",
            "195\n",
            "2867\n"
          ]
        }
      ]
    }
  ]
}