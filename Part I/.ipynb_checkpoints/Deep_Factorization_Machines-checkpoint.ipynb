{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-MKRhCyaxNU"
   },
   "source": [
    "# Deep Factorization Machines\n",
    "\n",
    "Deep neural networks are powerful in feature representation learning and have the potential to learn sophisticated feature interactions. As such, it is natural to integrate deep neural networks to factorization machines. Adding nonlinear transformation layers to factorization machines gives it the capability to model both low-order feature combinations and high-order feature combinations. Moreover, non-linear inherent structures from inputs can also be captured with deep neural networks. As such, we will train a representative model named deep factorization machines (DeepFM) [[Guo et al., 2017]](https://www.ijcai.org/Proceedings/2017/0239.pdf) which combines FM and deep neural networks.\n",
    "\n",
    "DeepFM consists of an FM component and a deep component which are integrated in a parallel structure. The FM component is the same as the 2-way factorization machines which is used to model the low-order feature interactions. The deep component is a multi-layered perceptron that is used to capture high-order feature interactions and nonlinearities. These two components share the same inputs/embeddings and their outputs are summed up as the final prediction. It is worth pointing out that the spirit of DeepFM resembles that of the Wide & Deep architecture which can capture both memorization and generalization. The advantages of DeepFM over the Wide & Deep model is that it reduces the effort of hand-crafted feature engineering by identifying feature combinations automatically.\n",
    "\n",
    "![](https://drive.google.com/uc?id=1KXC_8TRNC5Dj1w_NyDfyagzxAnbQDABb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rrT4wFPfn13"
   },
   "source": [
    "# Model implementation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HEtvOeO2fo-0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bpvQfBdWha-v"
   },
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    \"\"\"\n",
    "        MovieLens 1M Dataset\n",
    "        Data preparation: treat samples with a rating less than 3 as negative samples\n",
    "        :param dataset_path: MovieLens dataset path\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path, sep='::', engine='python', header=None):\n",
    "        # Read the data into a Pandas dataframe\n",
    "        data = pd.read_csv(dataset_path, sep=sep, engine=engine, header=header).to_numpy()[:, :3]\n",
    "\n",
    "        # Retrieve the items and ratings data\n",
    "        self.items = data[:, :2].astype(np.int) - 1  # -1 because ID begins from 1\n",
    "        self.targets = self.__preprocess_target(data[:, 2]).astype(np.float32)\n",
    "\n",
    "        # Get the range of the items\n",
    "        self.field_dims = np.max(self.items, axis=0) + 1\n",
    "\n",
    "        # Initialize NumPy arrays to store user and item indices\n",
    "        self.user_field_idx = np.array((0,), dtype=np.long)\n",
    "        self.item_field_idx = np.array((1,), dtype=np.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: number of total ratings\n",
    "        \"\"\"\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        :param index: current index\n",
    "        :return: the items and ratings at current index\n",
    "        \"\"\"\n",
    "        return self.items[index], self.targets[index]\n",
    "\n",
    "    def __preprocess_target(self, target):\n",
    "        \"\"\"\n",
    "        Preprocess the ratings into negative and positive samples\n",
    "        :param target: ratings\n",
    "        :return: binary ratings (0 or 1)\n",
    "        \"\"\"\n",
    "        target[target <= 3] = 0  # ratings less than or equal to 3 classified as 0\n",
    "        target[target > 3] = 1  # ratings bigger than 3 classified as 1\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WMRAINuohbBU"
   },
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    \"\"\"\n",
    "      A Pytorch implementation of Deep Factorization Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim, mlp_dims, dropout):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.linear = FeaturesLinear(field_dims)\n",
    "        self.fm = FactorizationMachine(reduce_sum=True)\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size (batch_size, num_fields)\n",
    "        \"\"\"\n",
    "        embed_x = self.embedding(x)\n",
    "        x = self.linear(x) + self.fm(embed_x) + self.mlp(embed_x.view(-1, self.embed_output_dim))\n",
    "        return torch.sigmoid(x.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9IBUI7MMn34w"
   },
   "outputs": [],
   "source": [
    "class FeaturesLinear(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Class to perform a linear transformation on the features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
    "\n",
    "    \n",
    "class FactorizationMachine(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Class to instantiate a Factorization Machine model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduce_sum=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix\n",
    "\n",
    "    \n",
    "class FeaturesEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Class to get feature embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Class to instantiate a Multilayer Perceptron model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in embed_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VJlQjuVohbJO"
   },
   "outputs": [],
   "source": [
    "def fit(model, optimizer, data_loader, criterion, device, log_interval=1000):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    :param model: choice of model\n",
    "    :param optimizer: choice of optimizer\n",
    "    :param data_loader: data loader class\n",
    "    :param criterion: choice of loss function\n",
    "    :param device: choice of device\n",
    "    :return: loss being logged\n",
    "    \"\"\"\n",
    "    # Step into train mode\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (fields, target) in enumerate(data_loader, smoothing=0, mininterval=1.0):\n",
    "        fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Log the total loss for every 1000 runs\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print('    - loss:', total_loss / log_interval)\n",
    "            total_loss = 0\n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model\n",
    "    :param model: choice of model\n",
    "    :param data_loader: data loader class\n",
    "    :param device: choice of device\n",
    "    :return: AUC score\n",
    "    \"\"\"\n",
    "    # Step into evaluation mode\n",
    "    model.eval()\n",
    "    targets, predicts = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in (data_loader, smoothing=0, mininterval=1.0):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "\n",
    "    # Return AUC score between predicted ratings and actual ratings\n",
    "    return roc_auc_score(targets, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVt7V-Amqjxz",
    "outputId": "e60d341f-7787-4fdd-ac1a-cc142e7f9232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-01 08:20:46--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: ‘ml-1m.zip’\n",
      "\n",
      "ml-1m.zip           100%[===================>]   5.64M  6.71MB/s    in 0.8s    \n",
      "\n",
      "2021-02-01 08:20:47 (6.71 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
      "\n",
      "Archive:  ml-1m.zip\n",
      "   creating: ml-1m/\n",
      "  inflating: ml-1m/movies.dat        \n",
      "  inflating: ml-1m/ratings.dat       \n",
      "  inflating: ml-1m/README            \n",
      "  inflating: ml-1m/users.dat         \n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "t2JJParYhbL8"
   },
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "dataset = MovieLensDataset('./ml-1m/ratings.dat')\n",
    "# Split the data into 80% train, 10% validation, and 10% test\n",
    "train_length = int(len(dataset) * 0.8)\n",
    "valid_length = int(len(dataset) * 0.1)\n",
    "test_length = len(dataset) - train_length - valid_length\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, (train_length, valid_length, test_length))\n",
    "\n",
    "# Instantiate data loader classes for train, validation, and test sets\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=512, num_workers=8)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=512, num_workers=8)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=512, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmBYa9qWq929",
    "outputId": "6533d1e1-da61-4118-8657-cfe3c6fcec61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 52/1563 [00:01<00:29, 51.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 122/1563 [00:02<00:23, 60.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 192/1563 [00:03<00:21, 63.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 262/1563 [00:04<00:20, 64.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 332/1563 [00:05<00:18, 65.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 402/1563 [00:06<00:17, 65.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 472/1563 [00:07<00:16, 66.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 542/1563 [00:08<00:15, 66.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 612/1563 [00:09<00:14, 66.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 682/1563 [00:10<00:13, 67.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 752/1563 [00:11<00:12, 67.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 822/1563 [00:12<00:10, 67.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 892/1563 [00:13<00:09, 67.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 962/1563 [00:14<00:08, 67.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.6690205756425858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|██████▌   | 1032/1563 [00:15<00:07, 67.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 1102/1563 [00:16<00:06, 67.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 1172/1563 [00:17<00:05, 67.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 1242/1563 [00:18<00:04, 67.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 1312/1563 [00:19<00:03, 67.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 1382/1563 [00:20<00:02, 67.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 1452/1563 [00:21<00:01, 67.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 67.60it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 165.68it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: auc: 0.7755284778642348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 55/1563 [00:01<00:27, 54.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 122/1563 [00:02<00:23, 60.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 189/1563 [00:03<00:21, 62.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 256/1563 [00:04<00:20, 63.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 323/1563 [00:05<00:19, 63.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 390/1563 [00:06<00:18, 63.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 457/1563 [00:07<00:17, 63.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 524/1563 [00:08<00:16, 63.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 591/1563 [00:09<00:15, 64.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 658/1563 [00:10<00:14, 64.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 725/1563 [00:11<00:13, 64.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 793/1563 [00:12<00:11, 64.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 861/1563 [00:13<00:10, 64.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 929/1563 [00:14<00:09, 64.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 997/1563 [00:15<00:08, 65.00it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5929096842706203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|██████▊   | 1065/1563 [00:16<00:07, 65.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 1133/1563 [00:17<00:06, 65.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 1201/1563 [00:18<00:05, 65.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 1271/1563 [00:19<00:04, 65.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 1341/1563 [00:20<00:03, 65.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 1411/1563 [00:21<00:02, 65.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1481/1563 [00:22<00:01, 65.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 65.99it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 164.86it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 validation: auc: 0.7819257846629311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 55/1563 [00:01<00:27, 54.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 125/1563 [00:02<00:23, 62.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 195/1563 [00:03<00:21, 64.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 265/1563 [00:04<00:19, 64.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 335/1563 [00:05<00:18, 65.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 405/1563 [00:06<00:17, 65.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 475/1563 [00:07<00:16, 65.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 545/1563 [00:08<00:15, 65.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 615/1563 [00:09<00:14, 65.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 685/1563 [00:10<00:13, 65.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 755/1563 [00:11<00:12, 65.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 825/1563 [00:12<00:11, 65.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 895/1563 [00:13<00:10, 66.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 965/1563 [00:14<00:09, 66.16it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5795797369480133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|██████▌   | 1035/1563 [00:15<00:07, 66.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 1105/1563 [00:16<00:06, 66.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 1175/1563 [00:17<00:05, 66.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 1245/1563 [00:18<00:04, 66.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 1315/1563 [00:19<00:03, 66.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 1385/1563 [00:20<00:02, 66.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 1455/1563 [00:21<00:01, 66.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.41it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 165.39it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 validation: auc: 0.7837620253504387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 56/1563 [00:01<00:27, 55.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 121/1563 [00:02<00:24, 59.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 189/1563 [00:03<00:22, 62.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 257/1563 [00:04<00:20, 63.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 325/1563 [00:05<00:19, 64.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 393/1563 [00:06<00:18, 64.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 461/1563 [00:07<00:16, 64.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 529/1563 [00:08<00:15, 65.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 597/1563 [00:09<00:14, 65.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 665/1563 [00:10<00:13, 65.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 733/1563 [00:11<00:12, 65.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 801/1563 [00:12<00:11, 65.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 870/1563 [00:13<00:10, 65.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 939/1563 [00:14<00:09, 65.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1008/1563 [00:15<00:08, 66.14it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.570320420563221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|██████▉   | 1077/1563 [00:16<00:07, 66.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1146/1563 [00:17<00:06, 66.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1216/1563 [00:18<00:05, 66.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 1286/1563 [00:19<00:04, 66.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 1356/1563 [00:20<00:03, 66.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 1426/1563 [00:21<00:02, 66.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.85it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 166.80it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 validation: auc: 0.7854718598679594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 56/1563 [00:01<00:27, 55.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 125/1563 [00:02<00:23, 62.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 194/1563 [00:03<00:21, 64.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 263/1563 [00:04<00:20, 64.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 332/1563 [00:05<00:18, 65.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 401/1563 [00:06<00:17, 66.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 470/1563 [00:07<00:16, 66.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 539/1563 [00:08<00:15, 66.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 608/1563 [00:09<00:14, 66.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 677/1563 [00:10<00:13, 66.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 746/1563 [00:11<00:12, 66.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 815/1563 [00:12<00:11, 66.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 884/1563 [00:13<00:10, 66.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 953/1563 [00:14<00:09, 66.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5616168911159038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|██████▌   | 1022/1563 [00:15<00:08, 66.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 1091/1563 [00:16<00:07, 66.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 1160/1563 [00:17<00:06, 66.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 1229/1563 [00:18<00:05, 66.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 1298/1563 [00:19<00:03, 66.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 1367/1563 [00:20<00:02, 66.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 1436/1563 [00:21<00:01, 66.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.76it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 165.91it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 validation: auc: 0.7866857788382037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 56/1563 [00:01<00:27, 55.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 123/1563 [00:02<00:23, 61.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 191/1563 [00:03<00:21, 63.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 259/1563 [00:04<00:20, 64.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 327/1563 [00:05<00:19, 64.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 396/1563 [00:06<00:17, 65.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 465/1563 [00:07<00:16, 65.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 534/1563 [00:08<00:15, 65.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 603/1563 [00:09<00:14, 66.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 672/1563 [00:10<00:13, 66.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 741/1563 [00:11<00:12, 66.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 810/1563 [00:12<00:11, 66.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 879/1563 [00:13<00:10, 66.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 948/1563 [00:14<00:09, 66.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5544778597950936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|██████▌   | 1017/1563 [00:15<00:08, 66.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 1086/1563 [00:16<00:07, 66.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 1155/1563 [00:17<00:06, 66.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1224/1563 [00:18<00:05, 66.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 1293/1563 [00:19<00:04, 66.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 1362/1563 [00:20<00:03, 66.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 1431/1563 [00:21<00:01, 66.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.81it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 165.62it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 validation: auc: 0.7879382728969546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 55/1563 [00:01<00:27, 54.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 122/1563 [00:02<00:23, 60.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 189/1563 [00:03<00:22, 62.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 256/1563 [00:04<00:20, 63.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 324/1563 [00:05<00:19, 64.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 392/1563 [00:06<00:18, 64.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 460/1563 [00:07<00:17, 64.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 528/1563 [00:08<00:15, 65.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 596/1563 [00:09<00:14, 65.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 664/1563 [00:10<00:13, 65.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 732/1563 [00:11<00:12, 65.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 800/1563 [00:12<00:11, 65.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 868/1563 [00:13<00:10, 65.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 936/1563 [00:14<00:09, 65.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1004/1563 [00:15<00:08, 65.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5480672477781773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|██████▊   | 1072/1563 [00:16<00:07, 65.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1140/1563 [00:17<00:06, 65.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 1208/1563 [00:18<00:05, 65.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 1276/1563 [00:19<00:04, 65.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 1344/1563 [00:20<00:03, 65.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 1412/1563 [00:21<00:02, 65.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1480/1563 [00:22<00:01, 65.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 65.73it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 167.19it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 validation: auc: 0.7897889501395793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 55/1563 [00:01<00:27, 54.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 125/1563 [00:02<00:23, 62.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 195/1563 [00:03<00:21, 64.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 265/1563 [00:04<00:19, 65.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 335/1563 [00:05<00:18, 65.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 405/1563 [00:06<00:17, 66.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 475/1563 [00:07<00:16, 66.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 545/1563 [00:08<00:15, 66.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 615/1563 [00:09<00:14, 66.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 685/1563 [00:10<00:13, 66.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 755/1563 [00:11<00:12, 66.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 825/1563 [00:12<00:11, 66.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 895/1563 [00:13<00:10, 66.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 965/1563 [00:14<00:08, 66.78it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5433256157934666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|██████▌   | 1035/1563 [00:15<00:07, 66.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 1105/1563 [00:16<00:06, 66.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 1175/1563 [00:17<00:05, 66.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 1245/1563 [00:18<00:04, 66.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 1315/1563 [00:19<00:03, 66.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 1385/1563 [00:20<00:02, 66.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 1455/1563 [00:21<00:01, 66.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.86it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 162.99it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 validation: auc: 0.7917325462634275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|▎         | 54/1563 [00:01<00:28, 52.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 120/1563 [00:02<00:24, 59.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 188/1563 [00:03<00:22, 62.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 256/1563 [00:04<00:20, 63.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 324/1563 [00:05<00:19, 63.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 392/1563 [00:06<00:18, 64.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 460/1563 [00:07<00:17, 64.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 528/1563 [00:08<00:15, 65.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 596/1563 [00:09<00:14, 65.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 664/1563 [00:10<00:13, 65.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 732/1563 [00:11<00:12, 65.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 800/1563 [00:12<00:11, 65.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 868/1563 [00:13<00:10, 65.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 936/1563 [00:14<00:09, 66.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1004/1563 [00:15<00:08, 66.16it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5392966420352459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|██████▊   | 1072/1563 [00:16<00:07, 66.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1140/1563 [00:17<00:06, 66.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 1208/1563 [00:18<00:05, 66.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 1277/1563 [00:19<00:04, 66.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 1346/1563 [00:20<00:03, 66.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 1415/1563 [00:21<00:02, 66.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1484/1563 [00:22<00:01, 66.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.48it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 166.45it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 validation: auc: 0.7922800231554454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 56/1563 [00:01<00:27, 55.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 124/1563 [00:02<00:23, 61.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 193/1563 [00:03<00:21, 63.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 262/1563 [00:04<00:20, 64.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 331/1563 [00:05<00:18, 65.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 400/1563 [00:06<00:17, 65.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 469/1563 [00:07<00:16, 65.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 538/1563 [00:08<00:15, 65.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 607/1563 [00:09<00:14, 66.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 676/1563 [00:10<00:13, 66.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 745/1563 [00:11<00:12, 66.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 814/1563 [00:12<00:11, 66.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 883/1563 [00:13<00:10, 66.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 952/1563 [00:14<00:09, 66.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - loss: 0.5344849933981896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|██████▌   | 1021/1563 [00:15<00:08, 66.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 1090/1563 [00:16<00:07, 66.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 1159/1563 [00:17<00:06, 66.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 1228/1563 [00:18<00:05, 66.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 1297/1563 [00:19<00:03, 66.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 1366/1563 [00:20<00:02, 66.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 1435/1563 [00:21<00:01, 66.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1563/1563 [00:23<00:00, 66.82it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 166.80it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 validation: auc: 0.7934295541700167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 196/196 [00:01<00:00, 165.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.7960322964431177\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "field_dims = dataset.field_dims\n",
    "learning_rate=0.001\n",
    "weight_decay=1e-6\n",
    "epoch=10\n",
    "device='cpu'\n",
    "\n",
    "model = DeepFM(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.5)\n",
    "# Use binary cross entropy loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "# Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Loop through pre-defined number of epochs\n",
    "for epoch_i in range(epoch):\n",
    "    # Perform training on the train set\n",
    "    fit(model, optimizer, train_data_loader, criterion, device)\n",
    "    # Perform evaluation on the validation set\n",
    "    valid_auc = test(model, valid_data_loader, device)\n",
    "    # Log the epochs and AUC on the validation set\n",
    "    print('epoch:', epoch_i, 'validation: auc:', valid_auc)\n",
    "\n",
    "# Perform evaluation on the test set\n",
    "test_auc = test(model, test_data_loader, device)\n",
    "# Log the final AUC on the test set\n",
    "print('test auc:', test_auc)\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'deepfm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lyhSdBMhbPA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnMKiB1lgA40"
   },
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp1v8uDYgBbM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Factorization Machines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
