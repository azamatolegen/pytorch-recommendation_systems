{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Factorization Machines.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-MKRhCyaxNU"
      },
      "source": [
        "# Deep Factorization Machines\r\n",
        "\r\n",
        "For real-world data where inherent feature crossing structures are usually very complex and nonlinear, second-order feature interactions  generally used in factorization machines in practice are often insufficient. Modeling higher degrees of feature combinations with factorization machines is possible theoretically but it is usually not adopted due to numerical instability and high computational complexity. One effective solution is using deep neural networks. \r\n",
        "\r\n",
        "Deep neural networks are powerful in feature representation learning and have the potential to learn sophisticated feature interactions. As such, it is natural to integrate deep neural networks to factorization machines. Adding nonlinear transformation layers to factorization machines gives it the capability to model both low-order feature combinations and high-order feature combinations. Moreover, non-linear inherent structures from inputs can also be captured with deep neural networks. As such, we will train a representative model named deep factorization machines (DeepFM) [Guo et al., 2017] which combine FM and deep neural networks.\r\n",
        "\r\n",
        "DeepFM consists of an FM component and a deep component which are integrated in a parallel structure. The FM component is the same as the 2-way factorization machines which is used to model the low-order feature interactions. The deep component is a multi-layered perceptron that is used to capture high-order feature interactions and nonlinearities. These two components share the same inputs/embeddings and their outputs are summed up as the final prediction. It is worth pointing out that the spirit of DeepFM resembles that of the Wide & Deep architecture which can capture both memorization and generalization. The advantages of DeepFM over the Wide & Deep model is that it reduces the effort of hand-crafted feature engineering by identifying feature combinations automatically.\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?id=1KXC_8TRNC5Dj1w_NyDfyagzxAnbQDABb)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rrT4wFPfn13"
      },
      "source": [
        "# Model implementation in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEtvOeO2fo-0"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tqdm\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpvQfBdWha-v"
      },
      "source": [
        "class MovieLensDataset(Dataset):\r\n",
        "    \"\"\"\r\n",
        "        MovieLens 1M Dataset\r\n",
        "        Data preparation: treat samples with a rating less than 3 as negative samples\r\n",
        "        :param dataset_path: MovieLens dataset path\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, dataset_path, sep='::', engine='python', header=None):\r\n",
        "        # Read the data into a Pandas dataframe\r\n",
        "        data = pd.read_csv(dataset_path, sep=sep, engine=engine, header=header).to_numpy()[:, :3]\r\n",
        "\r\n",
        "        # Retrieve the items and ratings data\r\n",
        "        self.items = data[:, :2].astype(np.int) - 1  # -1 because ID begins from 1\r\n",
        "        self.targets = self.__preprocess_target(data[:, 2]).astype(np.float32)\r\n",
        "\r\n",
        "        # Get the range of the items\r\n",
        "        self.field_dims = np.max(self.items, axis=0) + 1\r\n",
        "\r\n",
        "        # Initialize NumPy arrays to store user and item indices\r\n",
        "        self.user_field_idx = np.array((0,), dtype=np.long)\r\n",
        "        self.item_field_idx = np.array((1,), dtype=np.long)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        \"\"\"\r\n",
        "        :return: number of total ratings\r\n",
        "        \"\"\"\r\n",
        "        return self.targets.shape[0]\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"\r\n",
        "        :param index: current index\r\n",
        "        :return: the items and ratings at current index\r\n",
        "        \"\"\"\r\n",
        "        return self.items[index], self.targets[index]\r\n",
        "\r\n",
        "    def __preprocess_target(self, target):\r\n",
        "        \"\"\"\r\n",
        "        Preprocess the ratings into negative and positive samples\r\n",
        "        :param target: ratings\r\n",
        "        :return: binary ratings (0 or 1)\r\n",
        "        \"\"\"\r\n",
        "        target[target <= 3] = 0  # ratings less than or equal to 3 classified as 0\r\n",
        "        target[target > 3] = 1  # ratings bigger than 3 classified as 1\r\n",
        "        return target"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMRAINuohbBU"
      },
      "source": [
        "class DeepFM(nn.Module):\r\n",
        "  \"\"\"\r\n",
        "  A Pytorch implementation of Deep Factorization Model\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  def __init__(self, field_dims, embed_dim, mlp_dims, dropout):\r\n",
        "    super(DeepFM, self).__init__()\r\n",
        "    self.linear = FeaturesLinear(field_dims)\r\n",
        "    self.fm = FactorizationMachine(reduce_sum=True)\r\n",
        "    self.embedding = FeaturesEmbedding(field_dims, embed_dim)\r\n",
        "    self.embed_output_dim = len(field_dims) * embed_dim\r\n",
        "    self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    \"\"\"\r\n",
        "    :param x: Long tensor of size (batch_size, num_fields)\r\n",
        "    \"\"\"\r\n",
        "    embed_x = self.embedding(x)\r\n",
        "    x = self.linear(x) + self.fm(embed_x) + self.mlp(embed_x.view(-1, self.embed_output_dim))\r\n",
        "    return torch.sigmoid(x.squeeze(1))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IBUI7MMn34w"
      },
      "source": [
        "class FeaturesLinear(torch.nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Class to perform a linear transformation on the features\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, field_dims, output_dim=1):\r\n",
        "        super().__init__()\r\n",
        "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\r\n",
        "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\r\n",
        "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \"\"\"\r\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields)``\r\n",
        "        \"\"\"\r\n",
        "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\r\n",
        "        return torch.sum(self.fc(x), dim=1) + self.bias\r\n",
        "\r\n",
        "\r\n",
        "class FeaturesEmbedding(torch.nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Class to get feature embeddings\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, field_dims, embed_dim):\r\n",
        "        super().__init__()\r\n",
        "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\r\n",
        "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\r\n",
        "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \"\"\"\r\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields)``\r\n",
        "        \"\"\"\r\n",
        "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\r\n",
        "        return self.embedding(x)\r\n",
        "\r\n",
        "\r\n",
        "class MultiLayerPerceptron(torch.nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Class to instantiate a Multilayer Perceptron model\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\r\n",
        "        super().__init__()\r\n",
        "        layers = list()\r\n",
        "        for embed_dim in embed_dims:\r\n",
        "            layers.append(torch.nn.Linear(input_dim, embed_dim))\r\n",
        "            layers.append(torch.nn.BatchNorm1d(embed_dim))\r\n",
        "            layers.append(torch.nn.ReLU())\r\n",
        "            layers.append(torch.nn.Dropout(p=dropout))\r\n",
        "            input_dim = embed_dim\r\n",
        "        if output_layer:\r\n",
        "            layers.append(torch.nn.Linear(input_dim, 1))\r\n",
        "        self.mlp = torch.nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \"\"\"\r\n",
        "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\r\n",
        "        \"\"\"\r\n",
        "        return self.mlp(x)\r\n",
        "\r\n",
        "\r\n",
        "class FactorizationMachine(torch.nn.Module):\r\n",
        "    \"\"\"\r\n",
        "        Class to instantiate a Factorization Machine model\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, reduce_sum=True):\r\n",
        "        super().__init__()\r\n",
        "        self.reduce_sum = reduce_sum\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \"\"\"\r\n",
        "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\r\n",
        "        \"\"\"\r\n",
        "        square_of_sum = torch.sum(x, dim=1) ** 2\r\n",
        "        sum_of_square = torch.sum(x ** 2, dim=1)\r\n",
        "        ix = square_of_sum - sum_of_square\r\n",
        "        if self.reduce_sum:\r\n",
        "            ix = torch.sum(ix, dim=1, keepdim=True)\r\n",
        "        return 0.5 * ix"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJlQjuVohbJO"
      },
      "source": [
        "def fit(model, optimizer, data_loader, criterion, device, log_interval=1000):\r\n",
        "    \"\"\"\r\n",
        "    Train the model\r\n",
        "    :param model: choice of model\r\n",
        "    :param optimizer: choice of optimizer\r\n",
        "    :param data_loader: data loader class\r\n",
        "    :param criterion: choice of loss function\r\n",
        "    :param device: choice of device\r\n",
        "    :return: loss being logged\r\n",
        "    \"\"\"\r\n",
        "    # Step into train mode\r\n",
        "    model.train()\r\n",
        "    total_loss = 0\r\n",
        "    for i, (fields, target) in enumerate(tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0)):\r\n",
        "        fields, target = fields.to(device), target.to(device)\r\n",
        "        y = model(fields)\r\n",
        "        loss = criterion(y, target.float())\r\n",
        "        model.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Log the total loss for every 1000 runs\r\n",
        "        if (i + 1) % log_interval == 0:\r\n",
        "            print('    - loss:', total_loss / log_interval)\r\n",
        "            total_loss = 0\r\n",
        "\r\n",
        "def test(model, data_loader, device):\r\n",
        "    \"\"\"\r\n",
        "    Evaluate the model\r\n",
        "    :param model: choice of model\r\n",
        "    :param data_loader: data loader class\r\n",
        "    :param device: choice of device\r\n",
        "    :return: AUC score\r\n",
        "    \"\"\"\r\n",
        "    # Step into evaluation mode\r\n",
        "    model.eval()\r\n",
        "    targets, predicts = list(), list()\r\n",
        "    with torch.no_grad():\r\n",
        "        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0):\r\n",
        "            fields, target = fields.to(device), target.to(device)\r\n",
        "            y = model(fields)\r\n",
        "            targets.extend(target.tolist())\r\n",
        "            predicts.extend(y.tolist())\r\n",
        "\r\n",
        "    # Return AUC score between predicted ratings and actual ratings\r\n",
        "    return roc_auc_score(targets, predicts)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVt7V-Amqjxz",
        "outputId": "e60d341f-7787-4fdd-ac1a-cc142e7f9232"
      },
      "source": [
        "# get the data\r\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\r\n",
        "!unzip ml-1m.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-01 08:20:46--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  6.71MB/s    in 0.8s    \n",
            "\n",
            "2021-02-01 08:20:47 (6.71 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2JJParYhbL8"
      },
      "source": [
        "# Get the dataset\r\n",
        "dataset = MovieLensDataset('./ml-1m/ratings.dat')\r\n",
        "# Split the data into 80% train, 10% validation, and 10% test\r\n",
        "train_length = int(len(dataset) * 0.8)\r\n",
        "valid_length = int(len(dataset) * 0.1)\r\n",
        "test_length = len(dataset) - train_length - valid_length\r\n",
        "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\r\n",
        "    dataset, (train_length, valid_length, test_length))\r\n",
        "\r\n",
        "# Instantiate data loader classes for train, validation, and test sets\r\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=512, num_workers=8)\r\n",
        "valid_data_loader = DataLoader(valid_dataset, batch_size=512, num_workers=8)\r\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=512, num_workers=8)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmBYa9qWq929",
        "outputId": "6533d1e1-da61-4118-8657-cfe3c6fcec61"
      },
      "source": [
        "# Get the model\r\n",
        "field_dims = dataset.field_dims\r\n",
        "learning_rate=0.001\r\n",
        "weight_decay=1e-6\r\n",
        "epoch=10\r\n",
        "device='cpu'\r\n",
        "\r\n",
        "model = DeepFM(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.5)\r\n",
        "# Use binary cross entropy loss\r\n",
        "criterion = torch.nn.BCELoss()\r\n",
        "# Use Adam optimizer\r\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\r\n",
        "\r\n",
        "# Loop through pre-defined number of epochs\r\n",
        "for epoch_i in range(epoch):\r\n",
        "    # Perform training on the train set\r\n",
        "    fit(model, optimizer, train_data_loader, criterion, device)\r\n",
        "    # Perform evaluation on the validation set\r\n",
        "    valid_auc = test(model, valid_data_loader, device)\r\n",
        "    # Log the epochs and AUC on the validation set\r\n",
        "    print('epoch:', epoch_i, 'validation: auc:', valid_auc)\r\n",
        "\r\n",
        "# Perform evaluation on the test set\r\n",
        "test_auc = test(model, test_data_loader, device)\r\n",
        "# Log the final AUC on the test set\r\n",
        "print('test auc:', test_auc)\r\n",
        "\r\n",
        "# Save the model checkpoint\r\n",
        "torch.save(model.state_dict(), 'deepfm.pt')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 52/1563 [00:01<00:29, 51.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 122/1563 [00:02<00:23, 60.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 192/1563 [00:03<00:21, 63.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 262/1563 [00:04<00:20, 64.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 332/1563 [00:05<00:18, 65.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 402/1563 [00:06<00:17, 65.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 472/1563 [00:07<00:16, 66.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 542/1563 [00:08<00:15, 66.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 612/1563 [00:09<00:14, 66.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 682/1563 [00:10<00:13, 67.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 752/1563 [00:11<00:12, 67.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 822/1563 [00:12<00:10, 67.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 892/1563 [00:13<00:09, 67.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 962/1563 [00:14<00:08, 67.70it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.6690205756425858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 66%|██████▌   | 1032/1563 [00:15<00:07, 67.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 1102/1563 [00:16<00:06, 67.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 1172/1563 [00:17<00:05, 67.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 1242/1563 [00:18<00:04, 67.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 1312/1563 [00:19<00:03, 67.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 1382/1563 [00:20<00:02, 67.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 1452/1563 [00:21<00:01, 67.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 67.60it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 165.68it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 validation: auc: 0.7755284778642348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 55/1563 [00:01<00:27, 54.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 122/1563 [00:02<00:23, 60.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 189/1563 [00:03<00:21, 62.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 256/1563 [00:04<00:20, 63.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 323/1563 [00:05<00:19, 63.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 390/1563 [00:06<00:18, 63.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 457/1563 [00:07<00:17, 63.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 524/1563 [00:08<00:16, 63.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 591/1563 [00:09<00:15, 64.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 658/1563 [00:10<00:14, 64.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 725/1563 [00:11<00:13, 64.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 793/1563 [00:12<00:11, 64.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 861/1563 [00:13<00:10, 64.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 929/1563 [00:14<00:09, 64.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 997/1563 [00:15<00:08, 65.00it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5929096842706203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 68%|██████▊   | 1065/1563 [00:16<00:07, 65.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 1133/1563 [00:17<00:06, 65.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1201/1563 [00:18<00:05, 65.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 1271/1563 [00:19<00:04, 65.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 1341/1563 [00:20<00:03, 65.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 1411/1563 [00:21<00:02, 65.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 1481/1563 [00:22<00:01, 65.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 65.99it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 164.86it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 validation: auc: 0.7819257846629311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 55/1563 [00:01<00:27, 54.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 125/1563 [00:02<00:23, 62.00it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 195/1563 [00:03<00:21, 64.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 265/1563 [00:04<00:19, 64.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 335/1563 [00:05<00:18, 65.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 405/1563 [00:06<00:17, 65.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 475/1563 [00:07<00:16, 65.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 545/1563 [00:08<00:15, 65.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 615/1563 [00:09<00:14, 65.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 685/1563 [00:10<00:13, 65.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 755/1563 [00:11<00:12, 65.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 825/1563 [00:12<00:11, 65.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 895/1563 [00:13<00:10, 66.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 965/1563 [00:14<00:09, 66.16it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5795797369480133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 66%|██████▌   | 1035/1563 [00:15<00:07, 66.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 1105/1563 [00:16<00:06, 66.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 1175/1563 [00:17<00:05, 66.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 1245/1563 [00:18<00:04, 66.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 1315/1563 [00:19<00:03, 66.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 1385/1563 [00:20<00:02, 66.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 1455/1563 [00:21<00:01, 66.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.41it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 165.39it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 2 validation: auc: 0.7837620253504387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 56/1563 [00:01<00:27, 55.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 121/1563 [00:02<00:24, 59.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 189/1563 [00:03<00:22, 62.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 257/1563 [00:04<00:20, 63.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 325/1563 [00:05<00:19, 64.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 393/1563 [00:06<00:18, 64.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 461/1563 [00:07<00:16, 64.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 529/1563 [00:08<00:15, 65.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 597/1563 [00:09<00:14, 65.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 665/1563 [00:10<00:13, 65.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 733/1563 [00:11<00:12, 65.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 801/1563 [00:12<00:11, 65.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 870/1563 [00:13<00:10, 65.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 939/1563 [00:14<00:09, 65.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 1008/1563 [00:15<00:08, 66.14it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.570320420563221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 69%|██████▉   | 1077/1563 [00:16<00:07, 66.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 1146/1563 [00:17<00:06, 66.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 1216/1563 [00:18<00:05, 66.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 1286/1563 [00:19<00:04, 66.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 1356/1563 [00:20<00:03, 66.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 1426/1563 [00:21<00:02, 66.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.85it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 166.80it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 3 validation: auc: 0.7854718598679594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 56/1563 [00:01<00:27, 55.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 125/1563 [00:02<00:23, 62.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 194/1563 [00:03<00:21, 64.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 263/1563 [00:04<00:20, 64.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 332/1563 [00:05<00:18, 65.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 401/1563 [00:06<00:17, 66.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 470/1563 [00:07<00:16, 66.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 539/1563 [00:08<00:15, 66.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 608/1563 [00:09<00:14, 66.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 677/1563 [00:10<00:13, 66.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 746/1563 [00:11<00:12, 66.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 815/1563 [00:12<00:11, 66.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 884/1563 [00:13<00:10, 66.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 953/1563 [00:14<00:09, 66.54it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5616168911159038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 65%|██████▌   | 1022/1563 [00:15<00:08, 66.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 1091/1563 [00:16<00:07, 66.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 1160/1563 [00:17<00:06, 66.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 1229/1563 [00:18<00:05, 66.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 1298/1563 [00:19<00:03, 66.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 1367/1563 [00:20<00:02, 66.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 1436/1563 [00:21<00:01, 66.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.76it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 165.91it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 4 validation: auc: 0.7866857788382037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 56/1563 [00:01<00:27, 55.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 123/1563 [00:02<00:23, 61.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 191/1563 [00:03<00:21, 63.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 259/1563 [00:04<00:20, 64.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 327/1563 [00:05<00:19, 64.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 396/1563 [00:06<00:17, 65.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 465/1563 [00:07<00:16, 65.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 534/1563 [00:08<00:15, 65.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 603/1563 [00:09<00:14, 66.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 672/1563 [00:10<00:13, 66.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 741/1563 [00:11<00:12, 66.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 810/1563 [00:12<00:11, 66.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 879/1563 [00:13<00:10, 66.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 948/1563 [00:14<00:09, 66.51it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5544778597950936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 65%|██████▌   | 1017/1563 [00:15<00:08, 66.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 1086/1563 [00:16<00:07, 66.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 1155/1563 [00:17<00:06, 66.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 1224/1563 [00:18<00:05, 66.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 1293/1563 [00:19<00:04, 66.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 1362/1563 [00:20<00:03, 66.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 1431/1563 [00:21<00:01, 66.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.81it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 165.62it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 5 validation: auc: 0.7879382728969546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 55/1563 [00:01<00:27, 54.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 122/1563 [00:02<00:23, 60.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 189/1563 [00:03<00:22, 62.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 256/1563 [00:04<00:20, 63.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 324/1563 [00:05<00:19, 64.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 392/1563 [00:06<00:18, 64.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 460/1563 [00:07<00:17, 64.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 528/1563 [00:08<00:15, 65.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 596/1563 [00:09<00:14, 65.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 664/1563 [00:10<00:13, 65.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 732/1563 [00:11<00:12, 65.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 800/1563 [00:12<00:11, 65.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 868/1563 [00:13<00:10, 65.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 936/1563 [00:14<00:09, 65.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 1004/1563 [00:15<00:08, 65.38it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5480672477781773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 69%|██████▊   | 1072/1563 [00:16<00:07, 65.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 1140/1563 [00:17<00:06, 65.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1208/1563 [00:18<00:05, 65.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 1276/1563 [00:19<00:04, 65.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 1344/1563 [00:20<00:03, 65.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 1412/1563 [00:21<00:02, 65.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 1480/1563 [00:22<00:01, 65.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 65.73it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 167.19it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 6 validation: auc: 0.7897889501395793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 55/1563 [00:01<00:27, 54.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 125/1563 [00:02<00:23, 62.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 195/1563 [00:03<00:21, 64.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 265/1563 [00:04<00:19, 65.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 335/1563 [00:05<00:18, 65.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 405/1563 [00:06<00:17, 66.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 475/1563 [00:07<00:16, 66.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 545/1563 [00:08<00:15, 66.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 615/1563 [00:09<00:14, 66.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 685/1563 [00:10<00:13, 66.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 755/1563 [00:11<00:12, 66.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 825/1563 [00:12<00:11, 66.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 895/1563 [00:13<00:10, 66.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 965/1563 [00:14<00:08, 66.78it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5433256157934666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 66%|██████▌   | 1035/1563 [00:15<00:07, 66.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 1105/1563 [00:16<00:06, 66.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 1175/1563 [00:17<00:05, 66.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 1245/1563 [00:18<00:04, 66.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 1315/1563 [00:19<00:03, 66.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 1385/1563 [00:20<00:02, 66.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 1455/1563 [00:21<00:01, 66.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.86it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 162.99it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 7 validation: auc: 0.7917325462634275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  3%|▎         | 54/1563 [00:01<00:28, 52.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 120/1563 [00:02<00:24, 59.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 188/1563 [00:03<00:22, 62.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 256/1563 [00:04<00:20, 63.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 324/1563 [00:05<00:19, 63.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 392/1563 [00:06<00:18, 64.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 460/1563 [00:07<00:17, 64.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 528/1563 [00:08<00:15, 65.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 596/1563 [00:09<00:14, 65.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 664/1563 [00:10<00:13, 65.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 732/1563 [00:11<00:12, 65.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 800/1563 [00:12<00:11, 65.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 868/1563 [00:13<00:10, 65.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 936/1563 [00:14<00:09, 66.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 1004/1563 [00:15<00:08, 66.16it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5392966420352459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 69%|██████▊   | 1072/1563 [00:16<00:07, 66.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 1140/1563 [00:17<00:06, 66.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1208/1563 [00:18<00:05, 66.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 1277/1563 [00:19<00:04, 66.50it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 1346/1563 [00:20<00:03, 66.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 1415/1563 [00:21<00:02, 66.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 1484/1563 [00:22<00:01, 66.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.48it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 166.45it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 8 validation: auc: 0.7922800231554454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 56/1563 [00:01<00:27, 55.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 124/1563 [00:02<00:23, 61.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 193/1563 [00:03<00:21, 63.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 262/1563 [00:04<00:20, 64.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 331/1563 [00:05<00:18, 65.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 400/1563 [00:06<00:17, 65.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 469/1563 [00:07<00:16, 65.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 538/1563 [00:08<00:15, 65.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 607/1563 [00:09<00:14, 66.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 676/1563 [00:10<00:13, 66.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 745/1563 [00:11<00:12, 66.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 814/1563 [00:12<00:11, 66.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 883/1563 [00:13<00:10, 66.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 952/1563 [00:14<00:09, 66.68it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    - loss: 0.5344849933981896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 65%|██████▌   | 1021/1563 [00:15<00:08, 66.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 1090/1563 [00:16<00:07, 66.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 1159/1563 [00:17<00:06, 66.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 1228/1563 [00:18<00:05, 66.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 1297/1563 [00:19<00:03, 66.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 1366/1563 [00:20<00:02, 66.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 1435/1563 [00:21<00:01, 66.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1563/1563 [00:23<00:00, 66.82it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 166.80it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 9 validation: auc: 0.7934295541700167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 196/196 [00:01<00:00, 165.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test auc: 0.7960322964431177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lyhSdBMhbPA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnMKiB1lgA40"
      },
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp1v8uDYgBbM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}